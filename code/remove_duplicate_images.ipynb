{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove_duplicate_images.ipynb\n",
    "\n",
    "This notebook removes duplicate and near-duplicate images from the dataset.\n",
    "Duplicates and near-duplicatessuch wereas caused when multiple images are take at a single location because the survey vehicle had stopped.\n",
    "\n",
    "I followed the technique used in https://colab.research.google.com/github/voxel51/fiftyone-examples/blob/master/examples/image_deduplication.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "# import fiftyone.brain as fob\n",
    "from icecream import ic\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "import fiftyone.zoo as foz\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fo.load_dataset('dataset3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset:          dataset3\n",
       "Media type:       image\n",
       "Num samples:      70888\n",
       "Selected samples: 0\n",
       "Selected labels:  0\n",
       "Session URL:      http://localhost:5151/"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch app in browser\n",
    "session = fo.launch_app(dataset, auto=False)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        dataset3\n",
      "Media type:  image\n",
      "Num samples: 70888\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:                 fiftyone.core.fields.ObjectIdField\n",
      "    filepath:           fiftyone.core.fields.StringField\n",
      "    tags:               fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:           fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:         fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at:   fiftyone.core.fields.DateTimeField\n",
      "    ground_truth:       fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    YOLOv8_predictions: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    uniqueness:         fiftyone.core.fields.FloatField\n",
      "    max_similarity:     fiftyone.core.fields.FloatField\n",
      "    datetime:           fiftyone.core.fields.DateTimeField\n",
      "    embeddings:         fiftyone.core.fields.VectorField\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings\n",
    "\n",
    "Images store a lot of information in their pixel values. Comparing images pixel-by-pixel would be an expensive operation and result in poor quality results. \n",
    "\n",
    "Instead, we can use a pretrained computer vision model to generate embeddings for each image. An embedding is a result of processing an image through a model and extracting an intermediate representation of the image from within the model in the form of a vector containing a few thousand values distilling the information stored in the millions of pixels.\n",
    "\n",
    "For deep learning models, one typically uses the output of a fully-connected layer near the end of the forward pass to generate embeddings.\n",
    "\n",
    "The [FiftyOne Model Zoo](https://voxel51.com/docs/fiftyone/user_guide/model_zoo/index.html) contains a host of different pretrained models that we can use for this task. In this example, we will use a [MobileNet v2 model trained on ImageNet](https://voxel51.com/docs/fiftyone/user_guide/model_zoo/models.html#mobilenet-v2-imagenet-torch). This model provides relatively high performance, but most importantly is lightweight and can process our dataset quicker than other models. \n",
    "\n",
    "Any off-the-shelf model will be informative, but one can easily experiment with other models that may be more useful for particular datasets.\n",
    "\n",
    "We can easily load the model and compute embeddings on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = foz.load_zoo_model(\"mobilenet-v2-imagenet-torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = dataset.compute_embeddings(model=model, embeddings_field='embeddings')\n",
    "dataset.save()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic(embeddings.shape)\n",
    "# embeddings32 = embeddings.astype(np.float32)\n",
    "# print(embeddings32[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_datetime_view = dataset.sort_by('datetime')\n",
    "dataset.save_view('sorted_by_datatime_view', sorted_by_datetime_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['max_similarity_view', 'sorted_by_datatime_view']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.list_saved_views()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a,b)/(norm(a)*norm(b))\n",
    " \n",
    "# a = np.array([2,1,2,3,2,9])\n",
    "# b = np.array([3,4,2,4,5,5])\n",
    "# cosine_similarity(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_datetime_view = dataset.load_saved_view('sorted_by_datatime_view')\n",
    "\n",
    "thresh = 0.92\n",
    "\n",
    "first_sample = True\n",
    "for sample in sorted_by_datetime_view:\n",
    "    if first_sample:\n",
    "        current_embeddings = sample.embeddings\n",
    "        similarity = 0.0\n",
    "        first_sample = False\n",
    "    else:\n",
    "        previous_embeddings = current_embeddings\n",
    "        current_embeddings = sample.embeddings\n",
    "        similarity = cosine_similarity(previous_embeddings, current_embeddings)\n",
    "        sample['similarity_with_prev_img'] = similarity\n",
    "    if similarity > thresh:\n",
    "        sample.tags.append(f'similarity>{thresh}')\n",
    "    else:\n",
    "        sample.tags.append('similarity OK') \n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove samples (images) tagged with \"similarity OK\" and save in dataset4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024.11.14.08.24.25', 'dataset3', 'dataset4']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clone current dataset\n",
    "dataset4 = dataset.clone('dataset4', persistent=True)\n",
    "fo.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name:        dataset4\n",
       "Media type:  image\n",
       "Num samples: 59997\n",
       "Persistent:  True\n",
       "Tags:        []\n",
       "Sample fields:\n",
       "    id:                       fiftyone.core.fields.ObjectIdField\n",
       "    filepath:                 fiftyone.core.fields.StringField\n",
       "    tags:                     fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
       "    metadata:                 fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
       "    created_at:               fiftyone.core.fields.DateTimeField\n",
       "    last_modified_at:         fiftyone.core.fields.DateTimeField\n",
       "    ground_truth:             fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
       "    YOLOv8_predictions:       fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
       "    uniqueness:               fiftyone.core.fields.FloatField\n",
       "    max_similarity:           fiftyone.core.fields.FloatField\n",
       "    datetime:                 fiftyone.core.fields.DateTimeField\n",
       "    embeddings:               fiftyone.core.fields.VectorField\n",
       "    similarity_with_prev_img: fiftyone.core.fields.FloatField"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete tagged samples (images) and save new dataset\n",
    "\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "dataset = fo.load_dataset('dataset4')\n",
    "view = dataset.filter_field('tags', F().contains('similarity>0.92'))\n",
    "dataset.delete_samples(view)\n",
    "dataset.save()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name:        dataset4\n",
       "Media type:  image\n",
       "Num samples: 59997\n",
       "Persistent:  True\n",
       "Tags:        []\n",
       "Sample fields:\n",
       "    id:                       fiftyone.core.fields.ObjectIdField\n",
       "    filepath:                 fiftyone.core.fields.StringField\n",
       "    tags:                     fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
       "    metadata:                 fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
       "    created_at:               fiftyone.core.fields.DateTimeField\n",
       "    last_modified_at:         fiftyone.core.fields.DateTimeField\n",
       "    ground_truth:             fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
       "    YOLOv8_predictions:       fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
       "    uniqueness:               fiftyone.core.fields.FloatField\n",
       "    max_similarity:           fiftyone.core.fields.FloatField\n",
       "    datetime:                 fiftyone.core.fields.DateTimeField\n",
       "    embeddings:               fiftyone.core.fields.VectorField\n",
       "    similarity_with_prev_img: fiftyone.core.fields.FloatField"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check save dataset\n",
    "\n",
    "fo.load_dataset('dataset4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metadata...\n",
      " 100% |█████████████| 59997/59997 [14.8s elapsed, 0s remaining, 4.3K samples/s]      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'samples_count': 59997,\n",
       " 'samples_bytes': 353156633,\n",
       " 'samples_size': '336.8MB',\n",
       " 'media_bytes': 7188092459,\n",
       " 'media_size': '6.7GB',\n",
       " 'total_bytes': 7541249092,\n",
       " 'total_size': '7.0GB'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.stats(include_media=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity\n",
    "\n",
    "Now that we have significantly reduced the dimensionality of our images, we can use classical similarity algorithms to compute how similar every image embedding is to every other image embedding.\n",
    "\n",
    "In this case, we will use [cosine similarity provided by Scikit Learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) since this algorithm is simple and works fairly well in high dimensional spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "print(similarity_matrix.shape)\n",
    "print(similarity_matrix.dtype)\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all diagonal values are 1 since every image is identical to itself. We can subtract by the identity matrix (N x N matrix with 1's on the diagonal and 0's elsewhere) in order to zero out the diagonal so those values don't show up when we look for samples with maximum similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(similarity_matrix)\n",
    "similarity_matrix = similarity_matrix - np.identity(n, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(similarity_matrix.shape)\n",
    "print(similarity_matrix.dtype)\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and remove duplicates\n",
    "\n",
    "We can now iterate through every sample and find which other samples are the most similar to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = [s.id for s in dataset.select_fields([\"id\"])]\n",
    "\n",
    "for idx, sample in enumerate(dataset):\n",
    "    sample[\"max_similarity\"] = similarity_matrix[idx].max()\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Create a view\n",
    "max_similarity_view = (\n",
    "    dataset\n",
    "    .select_fields(\"max_similarity\")\n",
    "    .sort_by(F(\"max_similarity\"), reverse=True)\n",
    ")\n",
    "\n",
    "# Save the view\n",
    "dataset.save_view(\"max_similarity_view\", max_similarity_view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.list_saved_views()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime field\n",
    "for sample in dataset:\n",
    "    timestamp_str = os.path.basename(sample.filepath).replace('.jpg', '').replace('IMG', '').replace('_', '')\n",
    "    dt = datetime.strptime(timestamp_str, '%Y%m%d%H%M%S')\n",
    "    sample['datetime'] = dt\n",
    "    sample.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
