2024-11-23 13:24:32 Updating "requirements.txt"
2024-11-23 13:24:32 /home/aubrey/datasets/Guam07v3 already exists in YOLOv5 format
2024-11-23 13:24:32 FiftyOne dataset "Guam07v3" already exists
2024-11-23 13:24:32 Loading FiftyOne dataset "Guam07v3"
2024-11-23 13:24:32 timestamp field already exists
2024-11-23 13:24:32 embeddings field already exists
2024-11-23 13:24:32 similarity_with_prev_img field already exists
2024-11-23 13:24:32 yolov8 field already exists
2024-11-23 13:24:32 mistakenness field already exists
2024-11-23 13:24:32 Launching FifyOne app in browser
2024-11-23 13:24:32 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-23 13:24:32 Dataset:          Guam07v3
Media type:       image
Num samples:      10414
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-23 13:24:32 FINISHED
2024-11-23 15:18:26 Updating "requirements.txt"
2024-11-23 15:18:27 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-23 15:18:27 FiftyOne dataset "Guam07v3" already exists
2024-11-23 15:18:27 Loading FiftyOne dataset "Guam07v3"
2024-11-23 15:18:27 "timestamp" field already exists
2024-11-23 15:18:27 "embeddings" field already exists
2024-11-23 15:18:27 "similarity_with_prev_img" field already exists
2024-11-23 15:18:27 "yolov8" field already exists
2024-11-23 15:18:27 "mistakenness" field already exists
2024-11-23 15:18:27 Launching FifyOne app in browser
2024-11-23 15:18:27 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-23 15:18:27 Dataset:          Guam07v3
Media type:       image
Num samples:      10414
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-23 15:18:27 FINISHED
2024-11-24 07:06:14 Updating "requirements.txt"
2024-11-24 07:06:14 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 07:06:16 FiftyOne dataset "Guam07v3" already exists
2024-11-24 07:06:16 Loading FiftyOne dataset "Guam07v3"
2024-11-24 07:06:16 "timestamp" field already exists
2024-11-24 07:06:16 "embeddings" field already exists
2024-11-24 07:06:16 "similarity_with_prev_img" field already exists
2024-11-24 07:06:16 "yolov8" field already exists
2024-11-24 07:06:16 "mistakenness" field already exists
2024-11-24 07:06:16 Launching FifyOne app in browser
2024-11-24 07:06:18 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-24 07:06:18 Dataset:          Guam07v3
Media type:       image
Num samples:      10414
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-24 07:06:18 FINISHED
2024-11-24 09:16:14 Updating "requirements.txt"
2024-11-24 09:16:15 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 09:16:16 FiftyOne dataset "Guam07v3" already exists
2024-11-24 09:16:16 Loading FiftyOne dataset "Guam07v3"
2024-11-24 09:16:16 "timestamp" field already exists
2024-11-24 09:16:16 "embeddings" field already exists
2024-11-24 09:16:16 "similarity_with_prev_img" field already exists
2024-11-24 09:16:16 "yolov8" field already exists
2024-11-24 09:16:16 "mistakenness" field already exists
2024-11-24 09:16:16 Creating "autocorrelated_images_view"
2024-11-24 09:16:16 With a threshold of 0.98, 1455 autocorrelated images were found
2024-11-24 09:16:16 Launching FifyOne app in browser
2024-11-24 09:16:19 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-24 09:16:19 Dataset:          Guam07v3
Media type:       image
Num samples:      10414
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-24 09:16:19 FINISHED
2024-11-24 10:23:48 Updating "requirements.txt"
2024-11-24 10:23:48 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 10:23:50 FiftyOne dataset "Guam07v3" already exists
2024-11-24 10:23:50 Loading FiftyOne dataset "Guam07v3"
2024-11-24 10:23:50 "timestamp" field already exists
2024-11-24 10:23:50 "embeddings" field already exists
2024-11-24 10:23:50 "similarity_with_prev_img" field already exists
2024-11-24 10:23:50 "yolov8" field already exists
2024-11-24 10:23:50 "mistakenness" field already exists
2024-11-24 10:23:50 Creating "bb_touching_edge_view"
2024-11-24 10:24:54 Updating "requirements.txt"
2024-11-24 10:24:55 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 10:24:55 FiftyOne dataset "Guam07v3" already exists
2024-11-24 10:24:55 Loading FiftyOne dataset "Guam07v3"
2024-11-24 10:24:55 "timestamp" field already exists
2024-11-24 10:24:55 "embeddings" field already exists
2024-11-24 10:24:55 "similarity_with_prev_img" field already exists
2024-11-24 10:24:55 "yolov8" field already exists
2024-11-24 10:24:55 "mistakenness" field already exists
2024-11-24 10:24:55 Creating "bb_touching_edge_view"
2024-11-24 10:27:26 Updating "requirements.txt"
2024-11-24 10:27:27 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 10:27:27 FiftyOne dataset "Guam07v3" already exists
2024-11-24 10:27:27 Loading FiftyOne dataset "Guam07v3"
2024-11-24 10:27:27 "timestamp" field already exists
2024-11-24 10:27:27 "embeddings" field already exists
2024-11-24 10:27:27 "similarity_with_prev_img" field already exists
2024-11-24 10:27:27 "yolov8" field already exists
2024-11-24 10:27:27 "mistakenness" field already exists
2024-11-24 10:27:27 Creating "bb_touching_edge_view"
2024-11-24 10:27:27 4400 ground truth bounding boxes touching image edges were found
2024-11-24 10:27:27 Creating "autocorrelated_images_view"
2024-11-24 10:27:27 With a threshold of 0.98, 1455 autocorrelated images were found
2024-11-24 10:27:27 Launching FifyOne app in browser
2024-11-24 10:27:30 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-24 10:27:30 Dataset:          Guam07v3
Media type:       image
Num samples:      10414
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-24 10:27:30 FINISHED
2024-11-24 14:11:32 Updating "requirements.txt"
2024-11-24 14:11:33 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 14:11:35 FiftyOne dataset "Guam07v3" already exists
2024-11-24 14:11:35 Loading FiftyOne dataset "Guam07v3"
2024-11-24 14:11:35 "timestamp" field already exists
2024-11-24 14:11:35 "embeddings" field already exists
2024-11-24 14:11:35 "similarity_with_prev_img" field already exists
2024-11-24 14:11:35 "yolov8" field already exists
2024-11-24 14:11:35 "mistakenness" field already exists
2024-11-24 14:11:35 Creating "bb_touching_edge_view"
2024-11-24 14:11:35 -- "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted
2024-11-24 14:13:51 Updating "requirements.txt"
2024-11-24 14:13:52 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 14:13:52 FiftyOne dataset "Guam07v3" already exists
2024-11-24 14:13:52 Loading FiftyOne dataset "Guam07v3"
2024-11-24 14:13:52 "timestamp" field already exists
2024-11-24 14:13:52 "embeddings" field already exists
2024-11-24 14:13:52 "similarity_with_prev_img" field already exists
2024-11-24 14:13:52 "yolov8" field already exists
2024-11-24 14:13:52 "mistakenness" field already exists
2024-11-24 14:13:52 Creating "bb_touching_edge_view"
2024-11-24 14:13:52 -- "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted
2024-11-24 14:13:52 -- 4400 ground truth bounding boxes touching image edges were found
2024-11-24 14:13:52 Creating "autocorrelated_images_view"
2024-11-24 14:13:52 With a threshold of 0.98, 1455 autocorrelated images were found
2024-11-24 14:13:52 Launching FifyOne app in browser
2024-11-24 14:13:54 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-24 14:13:54 Dataset:          Guam07v3
Media type:       image
Num samples:      10414
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-24 14:13:54 FINISHED
2024-11-24 14:14:54 Updating "requirements.txt"
2024-11-24 14:14:54 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 14:14:54 FiftyOne dataset "Guam07v3" already exists
2024-11-24 14:14:54 Loading FiftyOne dataset "Guam07v3"
2024-11-24 14:14:54 "timestamp" field already exists
2024-11-24 14:14:54 "embeddings" field already exists
2024-11-24 14:14:54 "similarity_with_prev_img" field already exists
2024-11-24 14:14:54 "yolov8" field already exists
2024-11-24 14:14:54 "mistakenness" field already exists
2024-11-24 14:14:54 Creating "bb_touching_edge_view"
2024-11-24 14:14:54 -- "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted
2024-11-24 14:14:54 -- 4400 ground truth bounding boxes touching image edges were found
2024-11-24 14:14:54 Creating "autocorrelated_images_view"
2024-11-24 14:14:54 With a threshold of 0.98, 1455 autocorrelated images were found
2024-11-24 14:14:54 Launching FifyOne app in browser
2024-11-24 14:14:54 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-24 14:14:54 Dataset:          Guam07v3
Media type:       image
Num samples:      10414
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-24 14:14:54 FINISHED
2024-11-24 14:24:44 Updating "requirements.txt"
2024-11-24 14:24:44 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 14:24:44 FiftyOne dataset "Guam07v3" already exists
2024-11-24 14:24:44 Loading FiftyOne dataset "Guam07v3"
2024-11-24 14:24:44 "timestamp" field already exists
2024-11-24 14:24:44 "embeddings" field already exists
2024-11-24 14:24:44 "similarity_with_prev_img" field already exists
2024-11-24 14:24:44 "yolov8" field already exists
2024-11-24 14:24:44 "mistakenness" field already exists
2024-11-24 14:24:44 Creating "bb_touching_edge_view"
2024-11-24 14:24:44 -- "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted
2024-11-24 14:24:45 -- 0 ground truth bounding boxes touching image edges were found
2024-11-24 14:24:45 Creating "autocorrelated_images_view"
2024-11-24 14:24:45 With a threshold of 0.98, 1455 autocorrelated images were found
2024-11-24 14:24:45 Launching FifyOne app in browser
2024-11-24 14:24:45 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-24 14:24:45 Dataset:          Guam07v3
Media type:       image
Num samples:      10414
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-24 14:24:45 FINISHED
2024-11-24 15:08:24 Updating "requirements.txt"
2024-11-24 15:08:25 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 15:08:26 FiftyOne dataset "Guam07v3" already exists
2024-11-24 15:08:26 Loading FiftyOne dataset "Guam07v3"
2024-11-24 15:08:26 "timestamp" field already exists
2024-11-24 15:08:26 "embeddings" field already exists
2024-11-24 15:08:26 "similarity_with_prev_img" field already exists
2024-11-24 15:08:26 "yolov8" field already exists
2024-11-24 15:08:26 "mistakenness" field already exists
2024-11-24 15:08:26 Creating "bb_touching_edge_view"
2024-11-24 15:08:26     "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted
2024-11-24 15:08:26     0 ground truth bounding boxes touching image edges were found
2024-11-24 15:08:26 Creating "autocorrelated_images_view"
2024-11-24 15:08:26 With a threshold of 0.98, 1455 autocorrelated images were found
2024-11-24 15:08:26 Launching FifyOne app in browser
2024-11-24 15:08:29 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-24 15:08:29 Dataset:          Guam07v3
Media type:       image
Num samples:      10414
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-24 15:08:29 FINISHED
2024-11-24 15:15:06 Updating "requirements.txt"
2024-11-24 15:15:07 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 15:15:07 FiftyOne dataset "Guam07v3" already exists
2024-11-24 15:15:07 Loading FiftyOne dataset "Guam07v3"
2024-11-24 15:15:07 "timestamp" field already exists
2024-11-24 15:15:07 "embeddings" field already exists
2024-11-24 15:15:07 "similarity_with_prev_img" field already exists
2024-11-24 15:15:07 "yolov8" field already exists
2024-11-24 15:15:07 "mistakenness" field already exists
2024-11-24 15:15:07 Creating "bb_touching_edge_view"
2024-11-24 15:15:07     "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted
2024-11-24 15:15:07     0 ground truth bounding boxes touching image edges were found
2024-11-24 15:15:07 Creating "autocorrelated_images_view"
2024-11-24 15:15:07     "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted
2024-11-24 15:17:10 Updating "requirements.txt"
2024-11-24 15:17:10 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 15:17:10 FiftyOne dataset "Guam07v3" already exists
2024-11-24 15:17:10 Loading FiftyOne dataset "Guam07v3"
2024-11-24 15:17:10 "timestamp" field already exists
2024-11-24 15:17:10 "embeddings" field already exists
2024-11-24 15:17:10 "similarity_with_prev_img" field already exists
2024-11-24 15:17:10 "yolov8" field already exists
2024-11-24 15:17:10 "mistakenness" field already exists
2024-11-24 15:17:10 Creating "bb_touching_edge_view"
2024-11-24 15:17:10     "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted
2024-11-24 15:17:10     0 ground truth bounding boxes touching image edges were found
2024-11-24 15:17:10 Creating "autocorrelated_images_view"
2024-11-24 15:17:10     "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted
2024-11-24 15:24:43 Updating "requirements.txt"
2024-11-24 15:24:43 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 15:24:43 FiftyOne dataset "Guam07v3" already exists
2024-11-24 15:24:43 Loading FiftyOne dataset "Guam07v3"
2024-11-24 15:24:43 "timestamp" field already exists
2024-11-24 15:24:43 "embeddings" field already exists
2024-11-24 15:24:43 "similarity_with_prev_img" field already exists
2024-11-24 15:24:43 "yolov8" field already exists
2024-11-24 15:24:43 "mistakenness" field already exists
2024-11-24 15:24:43 Creating "bb_touching_edge_view"
2024-11-24 15:24:43     "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted
2024-11-24 15:24:44     0 ground truth bounding boxes touching image edges were found
2024-11-24 15:24:44 Creating "autocorrelated_images_view"
2024-11-24 15:24:44     "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted
2024-11-24 15:28:29 Updating "requirements.txt"
2024-11-24 15:28:29 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 15:28:29 FiftyOne dataset "Guam07v3" already exists
2024-11-24 15:28:29 Loading FiftyOne dataset "Guam07v3"
2024-11-24 15:28:29 "timestamp" field already exists
2024-11-24 15:28:29 "embeddings" field already exists
2024-11-24 15:28:29 "similarity_with_prev_img" field already exists
2024-11-24 15:28:29 "yolov8" field already exists
2024-11-24 15:28:29 "mistakenness" field already exists
2024-11-24 15:28:29 Creating "bb_touching_edge_view"
2024-11-24 15:28:29     "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted
2024-11-24 15:28:29     0 ground truth bounding boxes touching image edges were found
2024-11-24 15:28:29 Creating "autocorrelated_images_view"
2024-11-24 15:28:29     "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted
2024-11-24 15:39:21 Updating "requirements.txt"
2024-11-24 15:39:21 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 15:39:21 FiftyOne dataset "Guam07v3" already exists
2024-11-24 15:39:21 Loading FiftyOne dataset "Guam07v3"
2024-11-24 15:39:21 "timestamp" field already exists
2024-11-24 15:39:21 "embeddings" field already exists
2024-11-24 15:39:21 "similarity_with_prev_img" field already exists
2024-11-24 15:39:21 "yolov8" field already exists
2024-11-24 15:39:21 "mistakenness" field already exists
2024-11-24 15:39:21 Creating "bb_touching_edge_view"
2024-11-24 15:39:21     "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted
2024-11-24 15:39:22     0 ground truth bounding boxes touching image edges were found
2024-11-24 15:39:22 Creating "autocorrelated_images_view"
2024-11-24 15:39:22     "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted
2024-11-24 15:56:31 Updating "requirements.txt"
2024-11-24 15:56:31 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 15:56:33 FiftyOne dataset "Guam07v3" already exists
2024-11-24 15:56:33 Loading FiftyOne dataset "Guam07v3"
2024-11-24 15:56:33 "timestamp" field already exists
2024-11-24 15:56:33 "embeddings" field already exists
2024-11-24 15:56:33 "similarity_with_prev_img" field already exists
2024-11-24 15:56:33 "yolov8" field already exists
2024-11-24 15:56:33 "mistakenness" field already exists
2024-11-24 15:56:33 Creating "bb_touching_edge_view"
2024-11-24 15:56:33     "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted
2024-11-24 15:56:34     0 ground truth bounding boxes touching image edges were found
2024-11-24 15:56:34 Creating "autocorrelated_images_view"
2024-11-24 15:56:34     "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted
2024-11-24 15:56:34 With a threshold of 0.98, 0 autocorrelated images were found
2024-11-24 15:56:34 Launching FifyOne app in browser
2024-11-24 15:56:36 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-24 15:56:36 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-24 15:56:36 FINISHED
2024-11-24 16:23:20 Updating "requirements.txt"
2024-11-24 16:23:20 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 16:23:22 FiftyOne dataset "Guam07v3" already exists
2024-11-24 16:23:22 Loading FiftyOne dataset "Guam07v3"
2024-11-24 16:23:29 Ground truth bounding boxes: 14807
2024-11-24 16:23:29 "timestamp" field already exists
2024-11-24 16:23:29 "embeddings" field already exists
2024-11-24 16:23:29 "similarity_with_prev_img" field already exists
2024-11-24 16:23:29 "yolov8" field already exists
2024-11-24 16:23:29 "mistakenness" field already exists
2024-11-24 16:23:29 Creating "bb_touching_edge_view"
2024-11-24 16:23:29     "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted
2024-11-24 16:23:29     0 ground truth bounding boxes touching image edges were found
2024-11-24 16:23:29 Creating "autocorrelated_images_view"
2024-11-24 16:23:29     "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted
2024-11-24 16:23:29 With a threshold of 0.98, 0 autocorrelated images were found
2024-11-24 16:23:29 Loading FiftyOne dataset "Guam07v3"
2024-11-24 16:23:35 Ground truth bounding boxes: 14807
2024-11-24 16:23:35 Launching FifyOne app in browser
2024-11-24 16:23:38 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-24 16:23:38 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-24 16:24:42 Updating "requirements.txt"
2024-11-24 16:24:42 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-24 16:24:44 FiftyOne dataset "Guam07v3" already exists
2024-11-24 16:24:44 Loading FiftyOne dataset "Guam07v3"
2024-11-24 16:24:51 Ground truth bounding boxes: 14807
2024-11-24 16:24:51 "timestamp" field already exists
2024-11-24 16:24:51 "embeddings" field already exists
2024-11-24 16:24:51 "similarity_with_prev_img" field already exists
2024-11-24 16:24:51 "yolov8" field already exists
2024-11-24 16:24:51 "mistakenness" field already exists
2024-11-24 16:24:51 Creating "bb_touching_edge_view"
2024-11-24 16:24:51     "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted
2024-11-24 16:24:51     0 ground truth bounding boxes touching image edges were found
2024-11-24 16:24:51 Creating "autocorrelated_images_view"
2024-11-24 16:24:51     "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted
2024-11-24 16:24:51 With a threshold of 0.98, 0 autocorrelated images were found
2024-11-24 16:24:51 Loading FiftyOne dataset "Guam07v3"
2024-11-24 16:24:57 Ground truth bounding boxes: 14807
2024-11-24 16:24:57 Launching FifyOne app in browser
2024-11-24 16:25:00 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-24 16:25:00 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-24 16:25:00 FINISHED
2024-11-25 08:49:26 Updating "requirements.txt"
2024-11-25 08:49:27 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-25 08:49:29 FiftyOne dataset "Guam07v3" already exists
2024-11-25 08:49:29 Loading FiftyOne dataset "Guam07v3"
2024-11-25 08:49:35 Ground truth bounding boxes: 14807
2024-11-25 08:49:35 "timestamp" field already exists
2024-11-25 08:49:35 "embeddings" field already exists
2024-11-25 08:49:35 "similarity_with_prev_img" field already exists
2024-11-25 08:49:35 "yolov8" field already exists
2024-11-25 08:49:35 "mistakenness" field already exists
2024-11-25 08:49:35 Creating "bb_touching_edge_view"
2024-11-25 08:49:35     "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted
2024-11-25 08:49:35     0 ground truth bounding boxes touching image edges were found
2024-11-25 08:49:35 Creating "autocorrelated_images_view"
2024-11-25 08:49:35     "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted
2024-11-25 08:49:35 With a threshold of 0.98, 0 autocorrelated images were found
2024-11-25 08:49:35 Loading FiftyOne dataset "Guam07v3"
2024-11-25 08:49:42 Ground truth bounding boxes: 14807
2024-11-25 08:49:42 Launching FifyOne app in browser
2024-11-25 08:49:44 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-25 08:49:44 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-25 08:49:44 FINISHED
2024-11-25 08:58:44 Updating "requirements.txt"
2024-11-25 08:58:45 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-25 08:58:45 FiftyOne dataset "Guam07v3" already exists
2024-11-25 08:58:45 Loading FiftyOne dataset "Guam07v3"
2024-11-25 08:58:51 Ground truth bounding boxes: 14807
2024-11-25 08:58:51 "timestamp" field already exists
2024-11-25 08:58:51 "embeddings" field already exists
2024-11-25 08:58:51 "similarity_with_prev_img" field already exists
2024-11-25 08:58:51 "yolov8" field already exists
2024-11-25 08:58:51 "mistakenness" field already exists
2024-11-25 09:01:17 Updating "requirements.txt"
2024-11-25 09:01:17 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-25 09:01:17 FiftyOne dataset "Guam07v3" already exists
2024-11-25 09:01:17 Loading FiftyOne dataset "Guam07v3"
2024-11-25 09:01:24 Ground truth bounding boxes: 14807
2024-11-25 09:01:24 "timestamp" field already exists
2024-11-25 09:01:24 "embeddings" field already exists
2024-11-25 09:01:24 "similarity_with_prev_img" field already exists
2024-11-25 09:01:24 "yolov8" field already exists
2024-11-25 09:01:24 "mistakenness" field already exists
2024-11-25 09:02:52 Updating "requirements.txt"
2024-11-25 09:02:53 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-25 09:02:53 FiftyOne dataset "Guam07v3" already exists
2024-11-25 09:02:53 Loading FiftyOne dataset "Guam07v3"
2024-11-25 09:02:59 Ground truth bounding boxes: 14807
2024-11-25 09:02:59 "timestamp" field already exists
2024-11-25 09:02:59 "embeddings" field already exists
2024-11-25 09:02:59 "similarity_with_prev_img" field already exists
2024-11-25 09:02:59 "yolov8" field already exists
2024-11-25 09:02:59 "mistakenness" field already exists
2024-11-25 09:02:59 "bb_touching_edge_view" already exist
2024-11-25 09:02:59 "autocorrelated_images_view" already exists
2024-11-25 09:02:59 Loading FiftyOne dataset "Guam07v3"
2024-11-25 09:03:05 Ground truth bounding boxes: 14807
2024-11-25 09:03:05 Launching FifyOne app in browser
2024-11-25 09:03:05 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-25 09:03:05 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-25 09:03:05 FINISHED
2024-11-25 09:31:51  100% |███████████████| 8104/8104 [9.3s elapsed, 0s remaining, 948.8 samples/s]       
2024-11-25 09:31:51 Directory '/home/aubrey/myexport' already exists; export will be merged with existing files
2024-11-25 09:31:52  100% |█████████████████| 855/855 [997.2ms elapsed, 0s remaining, 886.1 samples/s]      
2024-11-25 10:25:16  100% |███████████████| 8104/8104 [9.2s elapsed, 0s remaining, 959.6 samples/s]       
2024-11-25 10:25:16 Directory '/home/aubrey/myexport' already exists; export will be merged with existing files
2024-11-25 10:25:17  100% |█████████████████| 855/855 [970.5ms elapsed, 0s remaining, 899.8 samples/s]      
2024-11-25 12:10:21 Directory '/home/aubrey/myexport' already exists; export will be merged with existing files
2024-11-25 12:10:32  100% |███████████████| 8104/8104 [10.5s elapsed, 0s remaining, 831.5 samples/s]      
2024-11-25 12:10:32 Directory '/home/aubrey/myexport' already exists; export will be merged with existing files
2024-11-25 12:10:33  100% |█████████████████| 855/855 [1.1s elapsed, 0s remaining, 807.5 samples/s]         
2024-11-25 12:30:45 Directory '/home/aubrey/myexport' already exists; export will be merged with existing files
2024-11-25 12:30:55  100% |███████████████| 8104/8104 [10.5s elapsed, 0s remaining, 823.1 samples/s]      
2024-11-25 12:30:55 Directory '/home/aubrey/myexport' already exists; export will be merged with existing files
2024-11-25 12:30:56  100% |█████████████████| 855/855 [1.1s elapsed, 0s remaining, 802.0 samples/s]         
2024-11-27 06:52:10 Updating "requirements.txt"
2024-11-27 06:52:10 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-27 06:52:12 FiftyOne dataset "Guam07v3" already exists
2024-11-27 06:52:12 Loading FiftyOne dataset "Guam07v3"
2024-11-27 06:52:19     Ground truth bounding boxes: 14807
2024-11-27 06:52:19 "timestamp" field already exists
2024-11-27 06:52:19 "embeddings" field already exists
2024-11-27 06:52:19 "similarity_with_prev_img" field already exists
2024-11-27 06:52:19 "yolov8" field already exists
2024-11-27 06:52:19 "mistakenness" field already exists
2024-11-27 06:52:19 "bb_touching_edge_view" already exist
2024-11-27 06:52:19 "autocorrelated_images_view" already exists
2024-11-27 06:52:19 Loading FiftyOne dataset "Guam07v3"
2024-11-27 06:52:26     Ground truth bounding boxes: 14807
2024-11-27 06:52:26 Launching FifyOne app in browser
2024-11-27 06:52:28 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-27 06:52:28 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-27 06:52:28 FINISHED
2024-11-27 07:17:37 Updating "requirements.txt"
2024-11-27 07:17:38 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-27 07:17:38 FiftyOne dataset "Guam07v3" already exists
2024-11-27 07:17:38 Loading FiftyOne dataset "Guam07v3"
2024-11-27 07:17:44     Ground truth bounding boxes: 14807
2024-11-27 07:17:44 "timestamp" field already exists
2024-11-27 07:17:44 "embeddings" field already exists
2024-11-27 07:17:44 "similarity_with_prev_img" field already exists
2024-11-27 07:17:44 "yolov8" field already exists
2024-11-27 07:17:44 "mistakenness" field already exists
2024-11-27 07:17:44 "bb_touching_edge_view" already exist
2024-11-27 07:17:44 "autocorrelated_images_view" already exists
2024-11-27 07:17:44 Loading FiftyOne dataset "Guam07v3"
2024-11-27 07:17:51     Ground truth bounding boxes: 14807
2024-11-27 07:17:51 Launching FifyOne app in browser
2024-11-27 07:17:51 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-27 07:17:51 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-27 07:17:51 FINISHED
2024-11-27 09:01:08 Updating "requirements.txt"
2024-11-27 09:01:08 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-27 09:01:08 FiftyOne dataset "Guam07v3" already exists
2024-11-27 09:01:08 Loading FiftyOne dataset "Guam07v3"
2024-11-27 09:01:15     Ground truth bounding boxes: 14807
2024-11-27 09:01:15 "timestamp" field already exists
2024-11-27 09:01:15 "embeddings" field already exists
2024-11-27 09:01:15 "similarity_with_prev_img" field already exists
2024-11-27 09:01:15 "yolov8" field already exists
2024-11-27 09:01:15 "mistakenness" field already exists
2024-11-27 09:01:15 "bb_touching_edge_view" already exists
2024-11-27 09:01:15 "autocorrelated_images_view" already exists
2024-11-27 09:01:15 Loading FiftyOne dataset "Guam07v3"
2024-11-27 09:01:21     Ground truth bounding boxes: 14807
2024-11-27 09:01:21 Launching FifyOne app in browser
2024-11-27 09:01:21 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-27 09:01:21 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-27 09:01:21 FINISHED
2024-11-27 09:49:45 {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'globals', 'globals()', 'locals()', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt')\n\n    results = model.train(\n        imgsz=1920,\n        data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=1000,\n        batch=-1,\n        patience=50,\n        name='newt'\n    )\n\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')'], '_oh': {1: <built-in function globals>, 2: {...}, 3: {...}}, '_dh': [PosixPath('/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code')], 'In': ['', 'globals', 'globals()', 'locals()', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt')\n\n    results = model.train(\n        imgsz=1920,\n        data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=1000,\n        batch=-1,\n        patience=50,\n        name='newt'\n    )\n\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')'], 'Out': {1: <built-in function globals>, 2: {...}, 3: {...}}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x702be275c760>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x702be275d390>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x702be275d390>, 'open': <function open at 0x702be5a130a0>, '_': {...}, '__': {...}, '___': <built-in function globals>, '__vsc_ipynb_file__': '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code/create_new_dataset.ipynb', '_i': 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '_ii': "def train_model():\n\n    model = YOLO('/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt')\n\n    results = model.train(\n        imgsz=1920,\n        data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=1000,\n        batch=-1,\n        patience=50,\n        name='newt'\n    )\n\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", '_iii': 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', '_i1': 'globals', '_1': <built-in function globals>, '_i2': 'globals()', '_2': {...}, '_i3': 'locals()', '_3': {...}, '_i4': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'os': <module 'os' from '/usr/lib/python3.10/os.py'>, 'shutil': <module 'shutil' from '/usr/lib/python3.10/shutil.py'>, 'glob': <module 'glob' from '/usr/lib/python3.10/glob.py'>, 'fo': <module 'fiftyone' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/__init__.py'>, 'fob': <module 'fiftyone.brain' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/brain/__init__.py'>, 'foz': <module 'fiftyone.zoo' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/zoo/__init__.py'>, 'F': <class 'fiftyone.core.expressions.ViewField'>, 'logging': <module 'logging' from '/usr/lib/python3.10/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'ic': <icecream.icecream.IceCreamDebugger object at 0x702b4ceaa350>, 'datetime': <class 'datetime.datetime'>, 'np': <module 'numpy' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/numpy/__init__.py'>, 'norm': <function norm at 0x702be0638e30>, 'YOLO': <class 'ultralytics.models.yolo.model.YOLO'>, '_i5': 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', 'add_timestamp_field': <function add_timestamp_field at 0x702a8fcf7880>, '_i6': "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'update_requirements_file': <function update_requirements_file at 0x702be1dd63b0>, '_i7': 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'create_new_dataset': <function create_new_dataset at 0x702be13411b0>, '_i8': 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'yolo2fiftyone': <function yolo2fiftyone at 0x702be278d990>, '_i9': 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'add_embeddings_field': <function add_embeddings_field at 0x702be1dd7910>, '_i10': 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'cosine_similarity': <function cosine_similarity at 0x702b4ce9fd90>, '_i11': 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'add_similarity_with_prev_img_field': <function add_similarity_with_prev_img_field at 0x702be1341480>, '_i12': 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'add_predictions_field': <function add_predictions_field at 0x702be13412d0>, '_i13': 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'add_mistakenness_field': <function add_mistakenness_field at 0x702a8e9e0b80>, '_i14': 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'add_field': <function add_field at 0x702a8e9e0e50>, '_i15': 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'create_autocorrelated_images_view': <function create_autocorrelated_images_view at 0x702a8e9e09d0>, '_i16': 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'count_ground_truth_bbs': <function count_ground_truth_bbs at 0x702a8e9e0dc0>, '_i17': 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'create_bb_touching_edge_view': <function create_bb_touching_edge_view at 0x702a8e9e0ee0>, '_i18': 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'remove_unannotated_images': <function remove_unannotated_images at 0x702a8e9e0f70>, '_i19': 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', 'export_51_to_YOLO': <function export_51_to_YOLO at 0x702a8e9e0ca0>, '_i20': "def train_model():\n\n    model = YOLO('/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt')\n\n    results = model.train(\n        imgsz=1920,\n        data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=1000,\n        batch=-1,\n        patience=50,\n        name='newt'\n    )\n\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", 'train_model': <function train_model at 0x702a8e9e0a60>, '_i21': 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', 'configure_logger': <function configure_logger at 0x702a8e9e1480>, '_i22': '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')', 'ORIGINAL_DS_PATH': '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks', 'ORIGINAL_MODEL_PATH': '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt', 'NEW_DS_PATH': '/home/aubrey/datasets/Guam07v3', 'FO_DATASET_NAME': 'Guam07v3', 'LOGFILE': 'create_new_dataset.log', 'AUTOCORRELATED_IMAGES_THRESHOLD': 0.98, 'DELETE_AUTOCORRELATED_IMAGES': True, 'DELETE_BBS_TOUCHING_EDGES': True, 'RETRAIN_MODEL': False, 'LAUNCH_51': True, 'logger': <RootLogger root (INFO)>}
2024-11-27 09:49:45 Updating "requirements.txt"
2024-11-27 09:49:45 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-27 09:49:47 FiftyOne dataset "Guam07v3" already exists
2024-11-27 09:49:47 Loading FiftyOne dataset "Guam07v3"
2024-11-27 09:49:54     Ground truth bounding boxes: 14807
2024-11-27 09:49:54 "timestamp" field already exists
2024-11-27 09:49:54 "embeddings" field already exists
2024-11-27 09:49:54 "similarity_with_prev_img" field already exists
2024-11-27 09:49:54 "yolov8" field already exists
2024-11-27 09:49:54 "mistakenness" field already exists
2024-11-27 09:49:54 "bb_touching_edge_view" already exists
2024-11-27 09:49:54 "autocorrelated_images_view" already exists
2024-11-27 09:49:54 Loading FiftyOne dataset "Guam07v3"
2024-11-27 09:50:00     Ground truth bounding boxes: 14807
2024-11-27 09:50:00 Launching FifyOne app in browser
2024-11-27 09:50:02 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-27 09:50:02 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-27 09:50:02 FINISHED
2024-11-27 12:08:10 {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", "get_ipython().run_line_magic('ls', '/home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt')", 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')'], '_oh': {}, '_dh': [PosixPath('/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code')], 'In': ['', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", "get_ipython().run_line_magic('ls', '/home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt')", 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7cc700b2c850>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x7cc700b2d480>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x7cc700b2d480>, 'open': <function open at 0x7cc7047270a0>, '_': '', '__': '', '___': '', '__vsc_ipynb_file__': '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code/create_new_dataset.ipynb', '_i': 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '_ii': 'ls /home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt', '_iii': "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", '_i1': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'os': <module 'os' from '/usr/lib/python3.10/os.py'>, 'shutil': <module 'shutil' from '/usr/lib/python3.10/shutil.py'>, 'glob': <module 'glob' from '/usr/lib/python3.10/glob.py'>, '_i2': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', '_i3': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', '_i4': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', '_i5': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', '_i6': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', 'fo': <module 'fiftyone' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/__init__.py'>, 'fob': <module 'fiftyone.brain' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/brain/__init__.py'>, 'foz': <module 'fiftyone.zoo' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/zoo/__init__.py'>, 'F': <class 'fiftyone.core.expressions.ViewField'>, 'logging': <module 'logging' from '/usr/lib/python3.10/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'ic': <icecream.icecream.IceCreamDebugger object at 0x7cc673598550>, 'datetime': <class 'datetime.datetime'>, 'np': <module 'numpy' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/numpy/__init__.py'>, 'norm': <function norm at 0x7cc6fabed170>, 'YOLO': <class 'ultralytics.models.yolo.model.YOLO'>, '_i7': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\n# import ipywidgets as widgets\n# from IPython.display import display', '_i8': 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', 'add_timestamp_field': <function add_timestamp_field at 0x7cc6e00be320>, '_i9': "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'update_requirements_file': <function update_requirements_file at 0x7cc67358b760>, '_i10': 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'create_new_dataset': <function create_new_dataset at 0x7cc700b59a20>, '_i11': 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'yolo2fiftyone': <function yolo2fiftyone at 0x7cc5b61c72e0>, '_i12': 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'add_embeddings_field': <function add_embeddings_field at 0x7cc5b4eabf40>, '_i13': 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'cosine_similarity': <function cosine_similarity at 0x7cc6d5f70ee0>, '_i14': 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'add_similarity_with_prev_img_field': <function add_similarity_with_prev_img_field at 0x7cc6735acee0>, '_i15': 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'add_predictions_field': <function add_predictions_field at 0x7cc6e001b910>, '_i16': 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'add_mistakenness_field': <function add_mistakenness_field at 0x7cc5b4ec4160>, '_i17': 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'add_field': <function add_field at 0x7cc5b4ec4430>, '_i18': 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'create_autocorrelated_images_view': <function create_autocorrelated_images_view at 0x7cc5b4ec41f0>, '_i19': 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'count_ground_truth_bbs': <function count_ground_truth_bbs at 0x7cc5b4ec43a0>, '_i20': 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'create_bb_touching_edge_view': <function create_bb_touching_edge_view at 0x7cc5b4ec44c0>, '_i21': 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'remove_unannotated_images': <function remove_unannotated_images at 0x7cc5b4ec4550>, '_i22': 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', 'export_51_to_YOLO': <function export_51_to_YOLO at 0x7cc5b4ec4280>, '_i23': "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", 'train_model': <function train_model at 0x7cc5b4ec49d0>, '_i24': 'ls /home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt', '_exit_code': 2, '_i25': 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', 'configure_logger': <function configure_logger at 0x7cc5b4ec4ca0>, '_i26': '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')', 'ORIGINAL_DS_PATH': '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks', 'ORIGINAL_MODEL_PATH': '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt', 'NEW_DS_PATH': '/home/aubrey/datasets/Guam07v3', 'FO_DATASET_NAME': 'Guam07v3', 'LOGFILE': 'create_new_dataset.log', 'AUTOCORRELATED_IMAGES_THRESHOLD': 0.98, 'DELETE_AUTOCORRELATED_IMAGES': True, 'DELETE_BBS_TOUCHING_EDGES': True, 'RETRAIN_MODEL': False, 'LAUNCH_51': True, 'logger': <RootLogger root (INFO)>}
2024-11-27 12:08:10 Updating "requirements.txt"
2024-11-27 12:08:11 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-27 12:08:13 FiftyOne dataset "Guam07v3" already exists
2024-11-27 12:08:13 Loading FiftyOne dataset "Guam07v3"
2024-11-27 12:08:19     Ground truth bounding boxes: 14807
2024-11-27 12:08:19 "timestamp" field already exists
2024-11-27 12:08:19 "embeddings" field already exists
2024-11-27 12:08:19 "similarity_with_prev_img" field already exists
2024-11-27 12:08:19 "yolov8" field already exists
2024-11-27 12:08:19 "mistakenness" field already exists
2024-11-27 12:08:19 "bb_touching_edge_view" already exists
2024-11-27 12:08:19 "autocorrelated_images_view" already exists
2024-11-27 12:08:19 Loading FiftyOne dataset "Guam07v3"
2024-11-27 12:08:26     Ground truth bounding boxes: 14807
2024-11-27 12:08:26 Launching FifyOne app in browser
2024-11-27 12:08:28 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-27 12:08:28 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-27 12:08:28 FINISHED
2024-11-27 12:37:53 Found existing field 'ground_truth' with multiple types ['detections', 'instances']. Only the 'detections' will be annotated
2024-11-27 12:37:53 Please enter your login credentials.
You can avoid this in the future by setting your `FIFTYONE_CVAT_USERNAME` and `FIFTYONE_CVAT_PASSWORD` environment variables
2024-11-27 13:12:41 {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport secrets.py\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport secrets.py\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport secrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\nos.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\n\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test\', label_field="ground_truth", launch_editor=True)', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", "get_ipython().run_line_magic('ls', '/home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt')", 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')'], '_oh': {}, '_dh': [PosixPath('/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code')], 'In': ['', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport secrets.py\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport secrets.py\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport secrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\nos.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\n\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test\', label_field="ground_truth", launch_editor=True)', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", "get_ipython().run_line_magic('ls', '/home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt')", 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f6f0c65c760>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x7f6f0c65d390>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x7f6f0c65d390>, 'open': <function open at 0x7f6f0efa30a0>, '_': '', '__': '', '___': '', '__vsc_ipynb_file__': '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code/create_new_dataset.ipynb', '_i': 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '_ii': 'ls /home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt', '_iii': "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", '_i1': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport secrets.py\n# import ipywidgets as widgets\n# from IPython.display import display', 'os': <module 'os' from '/usr/lib/python3.10/os.py'>, 'shutil': <module 'shutil' from '/usr/lib/python3.10/shutil.py'>, 'glob': <module 'glob' from '/usr/lib/python3.10/glob.py'>, 'fo': <module 'fiftyone' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/__init__.py'>, 'fob': <module 'fiftyone.brain' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/brain/__init__.py'>, 'foz': <module 'fiftyone.zoo' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/zoo/__init__.py'>, 'F': <class 'fiftyone.core.expressions.ViewField'>, 'logging': <module 'logging' from '/usr/lib/python3.10/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'ic': <icecream.icecream.IceCreamDebugger object at 0x7f6e763b6050>, 'datetime': <class 'datetime.datetime'>, 'np': <module 'numpy' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/numpy/__init__.py'>, 'norm': <function norm at 0x7f6f0f1ac970>, 'YOLO': <class 'ultralytics.models.yolo.model.YOLO'>, '_i2': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport secrets.py\n# import ipywidgets as widgets\n# from IPython.display import display', '_i3': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport secrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'secrets': <module 'secrets' from '/usr/lib/python3.10/secrets.py'>, '_i4': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'mysecrets': <module 'mysecrets' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code/mysecrets.py'>, '_i5': 'os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\nos.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\n\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test\', label_field="ground_truth", launch_editor=True)', '_i6': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', '_i7': 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', 'add_timestamp_field': <function add_timestamp_field at 0x7f6db7d96320>, '_i8': "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'update_requirements_file': <function update_requirements_file at 0x7f6db7d960e0>, '_i9': 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'create_new_dataset': <function create_new_dataset at 0x7f6db7d970a0>, '_i10': 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'yolo2fiftyone': <function yolo2fiftyone at 0x7f6db7d96d40>, '_i11': 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'add_embeddings_field': <function add_embeddings_field at 0x7f6db7d96440>, '_i12': 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'cosine_similarity': <function cosine_similarity at 0x7f6db7d95240>, '_i13': 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'add_similarity_with_prev_img_field': <function add_similarity_with_prev_img_field at 0x7f6db7d96f80>, '_i14': 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'add_predictions_field': <function add_predictions_field at 0x7f6db7d96c20>, '_i15': 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'add_mistakenness_field': <function add_mistakenness_field at 0x7f6db7d97370>, '_i16': 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'add_field': <function add_field at 0x7f6db7d971c0>, '_i17': 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'create_autocorrelated_images_view': <function create_autocorrelated_images_view at 0x7f6db7d96dd0>, '_i18': 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'count_ground_truth_bbs': <function count_ground_truth_bbs at 0x7f6db7d972e0>, '_i19': 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'create_bb_touching_edge_view': <function create_bb_touching_edge_view at 0x7f6db7d96170>, '_i20': 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'remove_unannotated_images': <function remove_unannotated_images at 0x7f6db7d97880>, '_i21': 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', 'export_51_to_YOLO': <function export_51_to_YOLO at 0x7f6db7d979a0>, '_i22': "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", 'train_model': <function train_model at 0x7f6db7d97b50>, '_i23': 'ls /home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt', '_exit_code': 2, '_i24': 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', 'configure_logger': <function configure_logger at 0x7f6db7d97eb0>, '_i25': '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')', 'ORIGINAL_DS_PATH': '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks', 'ORIGINAL_MODEL_PATH': '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt', 'NEW_DS_PATH': '/home/aubrey/datasets/Guam07v3', 'FO_DATASET_NAME': 'Guam07v3', 'LOGFILE': 'create_new_dataset.log', 'AUTOCORRELATED_IMAGES_THRESHOLD': 0.98, 'DELETE_AUTOCORRELATED_IMAGES': True, 'DELETE_BBS_TOUCHING_EDGES': True, 'RETRAIN_MODEL': False, 'LAUNCH_51': True, 'logger': <RootLogger root (INFO)>}
2024-11-27 13:12:41 Updating "requirements.txt"
2024-11-27 13:12:41 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-27 13:12:43 FiftyOne dataset "Guam07v3" already exists
2024-11-27 13:12:43 Loading FiftyOne dataset "Guam07v3"
2024-11-27 13:12:49     Ground truth bounding boxes: 14807
2024-11-27 13:12:49 "timestamp" field already exists
2024-11-27 13:12:49 "embeddings" field already exists
2024-11-27 13:12:49 "similarity_with_prev_img" field already exists
2024-11-27 13:12:49 "yolov8" field already exists
2024-11-27 13:12:49 "mistakenness" field already exists
2024-11-27 13:12:49 "bb_touching_edge_view" already exists
2024-11-27 13:12:49 "autocorrelated_images_view" already exists
2024-11-27 13:12:49 Loading FiftyOne dataset "Guam07v3"
2024-11-27 13:12:56     Ground truth bounding boxes: 14807
2024-11-27 13:12:56 Launching FifyOne app in browser
2024-11-27 13:12:58 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-27 13:12:58 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-27 13:12:58 FINISHED
2024-11-27 13:12:58 Found existing field 'ground_truth' with multiple types ['detections', 'instances']. Only the 'detections' will be annotated
2024-11-27 13:13:21 Found existing field 'ground_truth' with multiple types ['detections', 'instances']. Only the 'detections' will be annotated
2024-11-27 13:13:22 Please enter your login credentials.
You can avoid this in the future by setting your `FIFTYONE_CVAT_USERNAME` and `FIFTYONE_CVAT_PASSWORD` environment variables
2024-11-27 13:14:13 Found existing field 'ground_truth' with multiple types ['detections', 'instances']. Only the 'detections' will be annotated
2024-11-27 13:14:13 Please enter your login credentials.
You can avoid this in the future by setting your `FIFTYONE_CVAT_USERNAME` and `FIFTYONE_CVAT_PASSWORD` environment variables
2024-11-27 13:16:44 Found existing field 'ground_truth' with multiple types ['detections', 'instances']. Only the 'detections' will be annotated
2024-11-27 13:16:59 Found existing field 'ground_truth' with multiple types ['detections', 'instances']. Only the 'detections' will be annotated
2024-11-27 13:16:59 Please enter your login credentials.
You can avoid this in the future by setting your `FIFTYONE_CVAT_USERNAME` and `FIFTYONE_CVAT_PASSWORD` environment variables
2024-11-27 13:17:28 Computing metadata...
2024-11-27 13:17:28  100% |█████████████████| 100/100 [48.0ms elapsed, 0s remaining, 2.1K samples/s] 
2024-11-27 13:17:28 Uploading samples to CVAT...
2024-11-27 13:17:30 Launching editor at 'http://localhost:8080/tasks/1/jobs/1'...
2024-11-27 15:47:09 {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\n\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test3\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     )', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", "get_ipython().run_line_magic('ls', '/home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt')", 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')'], '_oh': {}, '_dh': [PosixPath('/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code')], 'In': ['', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\n\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test3\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     )', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", "get_ipython().run_line_magic('ls', '/home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt')", 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7815561607c0>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x781556161450>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x781556161450>, 'open': <function open at 0x78155940f0a0>, '_': '', '__': '', '___': '', '__vsc_ipynb_file__': '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code/create_new_dataset.ipynb', '_i': 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '_ii': 'ls /home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt', '_iii': "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", '_i1': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'os': <module 'os' from '/usr/lib/python3.10/os.py'>, 'shutil': <module 'shutil' from '/usr/lib/python3.10/shutil.py'>, 'glob': <module 'glob' from '/usr/lib/python3.10/glob.py'>, 'fo': <module 'fiftyone' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/__init__.py'>, 'fob': <module 'fiftyone.brain' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/brain/__init__.py'>, 'foz': <module 'fiftyone.zoo' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/zoo/__init__.py'>, 'F': <class 'fiftyone.core.expressions.ViewField'>, 'logging': <module 'logging' from '/usr/lib/python3.10/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'ic': <icecream.icecream.IceCreamDebugger object at 0x7814c8826140>, 'datetime': <class 'datetime.datetime'>, 'np': <module 'numpy' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/numpy/__init__.py'>, 'norm': <function norm at 0x781554029af0>, 'YOLO': <class 'ultralytics.models.yolo.model.YOLO'>, 'mysecrets': <module 'mysecrets' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code/mysecrets.py'>, '_i2': '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\n\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test3\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     )', '_i3': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', '_i4': 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', 'add_timestamp_field': <function add_timestamp_field at 0x7815561913f0>, '_i5': "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'update_requirements_file': <function update_requirements_file at 0x781556191870>, '_i6': 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'create_new_dataset': <function create_new_dataset at 0x78140a27d3f0>, '_i7': 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'yolo2fiftyone': <function yolo2fiftyone at 0x78140a27d7e0>, '_i8': 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'add_embeddings_field': <function add_embeddings_field at 0x78140a27e050>, '_i9': 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'cosine_similarity': <function cosine_similarity at 0x78140a27dab0>, '_i10': 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'add_similarity_with_prev_img_field': <function add_similarity_with_prev_img_field at 0x78140a27dd80>, '_i11': 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'add_predictions_field': <function add_predictions_field at 0x78140a27e170>, '_i12': 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'add_mistakenness_field': <function add_mistakenness_field at 0x78140a27d480>, '_i13': 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'add_field': <function add_field at 0x78140a27dbd0>, '_i14': 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'create_autocorrelated_images_view': <function create_autocorrelated_images_view at 0x78140a27d120>, '_i15': 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'count_ground_truth_bbs': <function count_ground_truth_bbs at 0x78140a27d090>, '_i16': 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'create_bb_touching_edge_view': <function create_bb_touching_edge_view at 0x78140a27cb80>, '_i17': 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'remove_unannotated_images': <function remove_unannotated_images at 0x78140a27d000>, '_i18': 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', 'export_51_to_YOLO': <function export_51_to_YOLO at 0x78140a27e200>, '_i19': "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", 'train_model': <function train_model at 0x78140a27dea0>, '_i20': 'ls /home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt', '_exit_code': 2, '_i21': 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', 'configure_logger': <function configure_logger at 0x78140a27e7a0>, '_i22': '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')', 'ORIGINAL_DS_PATH': '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks', 'ORIGINAL_MODEL_PATH': '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt', 'NEW_DS_PATH': '/home/aubrey/datasets/Guam07v3', 'FO_DATASET_NAME': 'Guam07v3', 'LOGFILE': 'create_new_dataset.log', 'AUTOCORRELATED_IMAGES_THRESHOLD': 0.98, 'DELETE_AUTOCORRELATED_IMAGES': True, 'DELETE_BBS_TOUCHING_EDGES': True, 'RETRAIN_MODEL': False, 'LAUNCH_51': True, 'logger': <RootLogger root (INFO)>}
2024-11-27 15:47:09 Updating "requirements.txt"
2024-11-27 15:47:10 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-27 15:47:11 FiftyOne dataset "Guam07v3" already exists
2024-11-27 15:47:11 Loading FiftyOne dataset "Guam07v3"
2024-11-27 15:47:18     Ground truth bounding boxes: 14807
2024-11-27 15:47:18 "timestamp" field already exists
2024-11-27 15:47:18 "embeddings" field already exists
2024-11-27 15:47:18 "similarity_with_prev_img" field already exists
2024-11-27 15:47:18 "yolov8" field already exists
2024-11-27 15:47:18 "mistakenness" field already exists
2024-11-27 15:47:18 "bb_touching_edge_view" already exists
2024-11-27 15:47:18 "autocorrelated_images_view" already exists
2024-11-27 15:47:18 Loading FiftyOne dataset "Guam07v3"
2024-11-27 15:47:25     Ground truth bounding boxes: 14807
2024-11-27 15:47:25 Launching FifyOne app in browser
2024-11-27 15:47:28 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-27 15:47:28 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-27 15:47:28 FINISHED
2024-11-27 15:47:28 Found existing field 'ground_truth' with multiple types ['detections', 'instances']. Only the 'detections' will be annotated
2024-11-27 15:48:46 Found existing field 'ground_truth' with multiple types ['detections', 'instances']. Only the 'detections' will be annotated
2024-11-27 15:49:26 Found existing field 'ground_truth' with multiple types ['detections', 'instances']. Only the 'detections' will be annotated
2024-11-27 15:49:27 Computing metadata...
2024-11-27 15:49:27  100% |███████████████████| 98/98 [66.5ms elapsed, 0s remaining, 1.5K samples/s] 
2024-11-27 15:49:27 Uploading samples to CVAT...
2024-11-27 15:49:29 Launching editor at 'http://localhost:8080/tasks/2/jobs/2'...
2024-11-27 17:26:24 Found existing field 'ground_truth' with multiple types ['detections', 'instances']. Only the 'detections' will be annotated
2024-11-27 17:28:12 Found existing field 'ground_truth' with multiple types ['detections', 'instances']. Only the 'detections' will be annotated
2024-11-27 17:28:12 Computing metadata...
2024-11-27 17:28:12  100% |███████████████████| 10/10 [5.0ms elapsed, 0s remaining, 2.0K samples/s] 
2024-11-27 17:28:12 Uploading samples to CVAT...
2024-11-27 17:28:14 Launching editor at 'http://localhost:8080/tasks/3/jobs/3'...
2024-11-27 17:31:05 Found existing field 'ground_truth' with multiple types ['detections', 'instances']. Only the 'detections' will be annotated
2024-11-27 17:31:06 Computing metadata...
2024-11-27 17:31:06  100% |███████████████████| 11/11 [4.9ms elapsed, 0s remaining, 2.2K samples/s] 
2024-11-27 17:31:06 Uploading samples to CVAT...
2024-11-27 17:31:07 Launching editor at 'http://localhost:8080/tasks/4/jobs/4'...
2024-11-27 17:36:48 {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\n\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test3\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     )', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", "get_ipython().run_line_magic('ls', '/home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt')", 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')', "# dataset.info['notes'] = 'Here is another note about this dataset.' \n# dataset.save()\n# dataset.info", '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test3\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     )', '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test3\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     );', '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test4\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     )', 'random_view = dataset.take(100)\nrandom_view.annotate(\n    anno_key=\'test4\', \n    label_field="ground_truth", \n    launch_editor=True,\n)?', "get_ipython().run_line_magic('pinfo', 'random_view.annotate')", 'type(random_view)', 'datetime.now()', "get_ipython().run_line_magic('pinfo', 'datetime.strptime')\ndatetime.now()", "get_ipython().run_line_magic('pinfo', 'datetime.strftime')\ndatetime.now()", "datetime.strftime(datetime.now(), '%YMDhm')", "datetime.strftime(datetime.now(), '%Y%M%D%h%m')", "datetime.strftime(datetime.now(), '%Y%m%d%H%M')", "datetime.strftime(datetime.now(), '%Y-%m-%d-%H-%M')", "datetime.strftime(datetime.now(), '%Y-%m-%d-%H:%M')", 'def launch_cvat(anno_key_suffix: str, view:fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key', 'def launch_cvat(anno_key_suffix: str, view:fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view:fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view:fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view: fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view: DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\nlaunch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y_%m_%d_%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\nlaunch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\nlaunch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')'], '_oh': {26: <fiftyone.utils.cvat.CVATAnnotationResults object at 0x781541a9afb0>, 29: <class 'fiftyone.core.view.DatasetView'>, 30: datetime.datetime(2024, 11, 27, 16, 50, 29, 982165), 31: datetime.datetime(2024, 11, 27, 16, 52, 16, 873362), 32: datetime.datetime(2024, 11, 27, 16, 52, 34, 916067), 33: '2024MDhm', 34: '20245311/27/24Nov11', 35: '202411271657', 36: '2024-11-27-16-57', 37: '2024-11-27-16:57', 42: <class 'fiftyone.core.view.DatasetView'>, 45: <class 'fiftyone.core.view.DatasetView'>, 47: 'random_dozen_2024_11_27_1728', 48: 'random_dozen_202411271731'}, '_dh': [PosixPath('/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code')], 'In': ['', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\n\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test3\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     )', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", "get_ipython().run_line_magic('ls', '/home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt')", 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')', "# dataset.info['notes'] = 'Here is another note about this dataset.' \n# dataset.save()\n# dataset.info", '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test3\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     )', '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test3\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     );', '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test4\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     )', 'random_view = dataset.take(100)\nrandom_view.annotate(\n    anno_key=\'test4\', \n    label_field="ground_truth", \n    launch_editor=True,\n)?', "get_ipython().run_line_magic('pinfo', 'random_view.annotate')", 'type(random_view)', 'datetime.now()', "get_ipython().run_line_magic('pinfo', 'datetime.strptime')\ndatetime.now()", "get_ipython().run_line_magic('pinfo', 'datetime.strftime')\ndatetime.now()", "datetime.strftime(datetime.now(), '%YMDhm')", "datetime.strftime(datetime.now(), '%Y%M%D%h%m')", "datetime.strftime(datetime.now(), '%Y%m%d%H%M')", "datetime.strftime(datetime.now(), '%Y-%m-%d-%H-%M')", "datetime.strftime(datetime.now(), '%Y-%m-%d-%H:%M')", 'def launch_cvat(anno_key_suffix: str, view:fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key', 'def launch_cvat(anno_key_suffix: str, view:fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view:fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view:fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view: fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view: DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\nlaunch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y_%m_%d_%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\nlaunch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\nlaunch_cvat(\'random_dozen\', random_dozen_view)', 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')'], 'Out': {26: <fiftyone.utils.cvat.CVATAnnotationResults object at 0x781541a9afb0>, 29: <class 'fiftyone.core.view.DatasetView'>, 30: datetime.datetime(2024, 11, 27, 16, 50, 29, 982165), 31: datetime.datetime(2024, 11, 27, 16, 52, 16, 873362), 32: datetime.datetime(2024, 11, 27, 16, 52, 34, 916067), 33: '2024MDhm', 34: '20245311/27/24Nov11', 35: '202411271657', 36: '2024-11-27-16-57', 37: '2024-11-27-16:57', 42: <class 'fiftyone.core.view.DatasetView'>, 45: <class 'fiftyone.core.view.DatasetView'>, 47: 'random_dozen_2024_11_27_1728', 48: 'random_dozen_202411271731'}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7815561607c0>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x781556161450>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x781556161450>, 'open': <function open at 0x78155940f0a0>, '_': 'random_dozen_202411271731', '__': 'random_dozen_2024_11_27_1728', '___': <class 'fiftyone.core.view.DatasetView'>, '__vsc_ipynb_file__': '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code/create_new_dataset.ipynb', '_i': 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '_ii': 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', '_iii': "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", '_i1': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'os': <module 'os' from '/usr/lib/python3.10/os.py'>, 'shutil': <module 'shutil' from '/usr/lib/python3.10/shutil.py'>, 'glob': <module 'glob' from '/usr/lib/python3.10/glob.py'>, 'fo': <module 'fiftyone' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/__init__.py'>, 'fob': <module 'fiftyone.brain' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/brain/__init__.py'>, 'foz': <module 'fiftyone.zoo' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/zoo/__init__.py'>, 'F': <class 'fiftyone.core.expressions.ViewField'>, 'logging': <module 'logging' from '/usr/lib/python3.10/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'ic': <icecream.icecream.IceCreamDebugger object at 0x7814c8826140>, 'datetime': <class 'datetime.datetime'>, 'np': <module 'numpy' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/numpy/__init__.py'>, 'norm': <function norm at 0x781554029af0>, 'YOLO': <class 'ultralytics.models.yolo.model.YOLO'>, 'mysecrets': <module 'mysecrets' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code/mysecrets.py'>, '_i2': '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\n\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test3\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     )', '_i3': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', '_i4': 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', 'add_timestamp_field': <function add_timestamp_field at 0x7815414fa050>, '_i5': "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'update_requirements_file': <function update_requirements_file at 0x781540c25bd0>, '_i6': 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'create_new_dataset': <function create_new_dataset at 0x781540c243a0>, '_i7': 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'yolo2fiftyone': <function yolo2fiftyone at 0x78154c2c8d30>, '_i8': 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'add_embeddings_field': <function add_embeddings_field at 0x7815414ff5b0>, '_i9': 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'cosine_similarity': <function cosine_similarity at 0x78140a27d3f0>, '_i10': 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'add_similarity_with_prev_img_field': <function add_similarity_with_prev_img_field at 0x78140a27de10>, '_i11': 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'add_predictions_field': <function add_predictions_field at 0x78140a27e050>, '_i12': 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'add_mistakenness_field': <function add_mistakenness_field at 0x78140a27d240>, '_i13': 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'add_field': <function add_field at 0x78140a27e170>, '_i14': 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'create_autocorrelated_images_view': <function create_autocorrelated_images_view at 0x78140a27d480>, '_i15': 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'count_ground_truth_bbs': <function count_ground_truth_bbs at 0x78140a27d7e0>, '_i16': 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'create_bb_touching_edge_view': <function create_bb_touching_edge_view at 0x78140a27d120>, '_i17': 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'remove_unannotated_images': <function remove_unannotated_images at 0x78140a27d1b0>, '_i18': 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', 'export_51_to_YOLO': <function export_51_to_YOLO at 0x78140a27e290>, '_i19': "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", 'train_model': <function train_model at 0x78140a27e3b0>, '_i20': 'ls /home/aubrey/label-studio-ml-backend/runs/dataset/newt/weights/best.pt', '_exit_code': 2, '_i21': 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', 'configure_logger': <function configure_logger at 0x78140a27e200>, '_i22': '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')', 'ORIGINAL_DS_PATH': '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks', 'ORIGINAL_MODEL_PATH': '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt', 'NEW_DS_PATH': '/home/aubrey/datasets/Guam07v3', 'FO_DATASET_NAME': 'Guam07v3', 'LOGFILE': 'create_new_dataset.log', 'AUTOCORRELATED_IMAGES_THRESHOLD': 0.98, 'DELETE_AUTOCORRELATED_IMAGES': True, 'DELETE_BBS_TOUCHING_EDGES': True, 'RETRAIN_MODEL': False, 'LAUNCH_51': True, 'logger': <RootLogger root (INFO)>, 'dataset': Name:        Guam07v3
Media type:  image
Num samples: 8959
Persistent:  True
Tags:        []
Sample fields:
    id:                       fiftyone.core.fields.ObjectIdField
    filepath:                 fiftyone.core.fields.StringField
    tags:                     fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)
    metadata:                 fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)
    created_at:               fiftyone.core.fields.DateTimeField
    last_modified_at:         fiftyone.core.fields.DateTimeField
    ground_truth:             fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)
    timestamp:                fiftyone.core.fields.DateTimeField
    embeddings:               fiftyone.core.fields.VectorField
    similarity_with_prev_img: fiftyone.core.fields.FloatField
    yolov8:                   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)
    mistakenness:             fiftyone.core.fields.FloatField
    possible_missing:         fiftyone.core.fields.IntField
    possible_spurious:        fiftyone.core.fields.IntField, 'session': Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/, '_i23': "# dataset.info['notes'] = 'Here is another note about this dataset.' \n# dataset.save()\n# dataset.info", '_i24': '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test3\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     )', 'random_view': Dataset:     Guam07v3
Media type:  image
Num samples: 100
Sample fields:
    id:                       fiftyone.core.fields.ObjectIdField
    filepath:                 fiftyone.core.fields.StringField
    tags:                     fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)
    metadata:                 fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)
    created_at:               fiftyone.core.fields.DateTimeField
    last_modified_at:         fiftyone.core.fields.DateTimeField
    ground_truth:             fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)
    timestamp:                fiftyone.core.fields.DateTimeField
    embeddings:               fiftyone.core.fields.VectorField
    similarity_with_prev_img: fiftyone.core.fields.FloatField
    yolov8:                   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)
    mistakenness:             fiftyone.core.fields.FloatField
    possible_missing:         fiftyone.core.fields.IntField
    possible_spurious:        fiftyone.core.fields.IntField
View stages:
    1. Take(size=100, seed=None), '_i25': '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test3\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     );', '_i26': '# os.environ["FIFTYONE_CVAT_USERNAME"] = mysecrets.FIFTYONE_CVAT_USERNAME\n# os.environ[\'FIFTYONE_CVAT_PASSWORD\'] = mysecrets.FIFTYONE_CVAT_PASSWORD\nrandom_view = dataset.take(100)\nrandom_view.annotate(anno_key=\'test4\', \n                     label_field="ground_truth", \n                     launch_editor=True,\n                     )', '_26': <fiftyone.utils.cvat.CVATAnnotationResults object at 0x781541a9afb0>, '_i27': 'random_view = dataset.take(100)\nrandom_view.annotate(\n    anno_key=\'test4\', \n    label_field="ground_truth", \n    launch_editor=True,\n)?', '_i28': 'random_view.annotate?', '_i29': 'type(random_view)', '_29': <class 'fiftyone.core.view.DatasetView'>, '_i30': 'datetime.now()', '_30': datetime.datetime(2024, 11, 27, 16, 50, 29, 982165), '_i31': 'datetime.strptime?\ndatetime.now()', '_31': datetime.datetime(2024, 11, 27, 16, 52, 16, 873362), '_i32': 'datetime.strftime?\ndatetime.now()', '_32': datetime.datetime(2024, 11, 27, 16, 52, 34, 916067), '_i33': "datetime.strftime(datetime.now(), '%YMDhm')", '_33': '2024MDhm', '_i34': "datetime.strftime(datetime.now(), '%Y%M%D%h%m')", '_34': '20245311/27/24Nov11', '_i35': "datetime.strftime(datetime.now(), '%Y%m%d%H%M')", '_35': '202411271657', '_i36': "datetime.strftime(datetime.now(), '%Y-%m-%d-%H-%M')", '_36': '2024-11-27-16-57', '_i37': "datetime.strftime(datetime.now(), '%Y-%m-%d-%H:%M')", '_37': '2024-11-27-16:57', '_i38': 'def launch_cvat(anno_key_suffix: str, view:fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key', '_i39': 'def launch_cvat(anno_key_suffix: str, view:fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', '_i40': 'def launch_cvat(anno_key_suffix: str, view:fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', '_i41': 'def launch_cvat(anno_key_suffix: str, view:fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', '_i42': 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'launch_cvat': <function launch_cvat at 0x78140a27d090>, 'random_dozen_view': Dataset:     Guam07v3
Media type:  image
Num samples: 12
Sample fields:
    id:                       fiftyone.core.fields.ObjectIdField
    filepath:                 fiftyone.core.fields.StringField
    tags:                     fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)
    metadata:                 fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)
    created_at:               fiftyone.core.fields.DateTimeField
    last_modified_at:         fiftyone.core.fields.DateTimeField
    ground_truth:             fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)
    timestamp:                fiftyone.core.fields.DateTimeField
    embeddings:               fiftyone.core.fields.VectorField
    similarity_with_prev_img: fiftyone.core.fields.FloatField
    yolov8:                   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)
    mistakenness:             fiftyone.core.fields.FloatField
    possible_missing:         fiftyone.core.fields.IntField
    possible_spurious:        fiftyone.core.fields.IntField
View stages:
    1. Take(size=12, seed=None), '_42': <class 'fiftyone.core.view.DatasetView'>, '_i43': 'def launch_cvat(anno_key_suffix: str, view: fiftyone.core.view.DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', '_i44': 'def launch_cvat(anno_key_suffix: str, view: DatasetView) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', '_i45': 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\ntype(random_dozen_view)\n# launch_cvat(\'random_dozen\', random_dozen_view)', '_45': <class 'fiftyone.core.view.DatasetView'>, '_i46': 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y-%m-%d-%H:%M\')\n    anno_key = f\'{anno_key_suffix}-{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\nlaunch_cvat(\'random_dozen\', random_dozen_view)', '_i47': 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y_%m_%d_%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\nlaunch_cvat(\'random_dozen\', random_dozen_view)', '_47': 'random_dozen_2024_11_27_1728', '_i48': 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \nrandom_dozen_view = dataset.take(12)\nlaunch_cvat(\'random_dozen\', random_dozen_view)', '_48': 'random_dozen_202411271731', '_i49': 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', '_i50': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', '_i51': 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', '_i52': "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", '_i53': 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', '_i54': 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', '_i55': 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', '_i56': 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', '_i57': 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', '_i58': 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', '_i59': 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', '_i60': 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', '_i61': 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', '_i62': 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', '_i63': 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', '_i64': 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', '_i65': 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', '_i66': "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", '_i67': 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', '_i68': 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '_i69': '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')', '__warningregistry__': {'version': 454}}
2024-11-27 17:36:48 Updating "requirements.txt"
2024-11-27 17:36:49 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-27 17:36:49 FiftyOne dataset "Guam07v3" already exists
2024-11-27 17:36:49 Loading FiftyOne dataset "Guam07v3"
2024-11-27 17:36:55     Ground truth bounding boxes: 14807
2024-11-27 17:36:55 "timestamp" field already exists
2024-11-27 17:36:55 "embeddings" field already exists
2024-11-27 17:36:55 "similarity_with_prev_img" field already exists
2024-11-27 17:36:55 "yolov8" field already exists
2024-11-27 17:36:55 "mistakenness" field already exists
2024-11-27 17:36:55 "bb_touching_edge_view" already exists
2024-11-27 17:36:55 "autocorrelated_images_view" already exists
2024-11-27 17:36:55 Loading FiftyOne dataset "Guam07v3"
2024-11-27 17:37:02     Ground truth bounding boxes: 14807
2024-11-27 17:37:02 Launching FifyOne app in browser
2024-11-27 17:37:02 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-27 17:37:02 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-27 17:37:02 FINISHED
2024-11-27 17:41:07 {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')'], '_oh': {}, '_dh': [PosixPath('/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code')], 'In': ['', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob', 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob', 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x74cf82960760>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x74cf829613f0>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x74cf829613f0>, 'open': <function open at 0x74cf8529f0a0>, '_': '', '__': '', '___': '', '__vsc_ipynb_file__': '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/code/create_new_dataset.ipynb', '_i': 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', '_ii': 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', '_iii': "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", '_i1': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob\nimport mysecrets\n# import ipywidgets as widgets\n# from IPython.display import display', 'os': <module 'os' from '/usr/lib/python3.10/os.py'>, 'shutil': <module 'shutil' from '/usr/lib/python3.10/shutil.py'>, 'glob': <module 'glob' from '/usr/lib/python3.10/glob.py'>, 'fo': <module 'fiftyone' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/__init__.py'>, 'fob': <module 'fiftyone.brain' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/brain/__init__.py'>, 'foz': <module 'fiftyone.zoo' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/fiftyone/zoo/__init__.py'>, 'F': <class 'fiftyone.core.expressions.ViewField'>, 'logging': <module 'logging' from '/usr/lib/python3.10/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'ic': <icecream.icecream.IceCreamDebugger object at 0x74cef47120b0>, 'datetime': <class 'datetime.datetime'>, 'np': <module 'numpy' from '/home/aubrey/datasets/dataset5/CRB-Damage-Dataset-Improvement/.venv/lib/python3.10/site-packages/numpy/__init__.py'>, 'norm': <function norm at 0x74cf7bf20df0>, 'YOLO': <class 'ultralytics.models.yolo.model.YOLO'>, '_i2': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob', '_i3': 'import os\nimport shutil\nimport glob\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\nimport logging\nimport sys\nfrom icecream import ic\nfrom datetime import datetime\nimport numpy as np\nfrom numpy.linalg import norm\nfrom ultralytics import YOLO\nimport glob', '_i4': 'def add_timestamp_field():\n    dataset.add_sample_field("timestamp", fo.DateTimeField)\n\n    for sample in dataset:\n        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n        dt = datetime.strptime(timestamp_str, \'%Y%m%d_%H%M%S\')\n        # ic(timestamp_str, dt)\n        sample[\'timestamp\'] = dt\n        sample.save()\n    \n    # Create view  \n    view = dataset.sort_by(F\'timestamp\')\n    dataset.save_view(\'sorted_by_timestamp\', view, overwrite=True)', 'add_timestamp_field': <function add_timestamp_field at 0x74cf82991a20>, '_i5': "def update_requirements_file():\n    os.system('pip list --format=freeze > requirements.txt')\n\n# update_requirements_file()", 'update_requirements_file': <function update_requirements_file at 0x74cf82991990>, '_i6': 'def create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH):\n    """ \n    """\n    os.mkdir(NEW_DS_PATH)\n    os.mkdir(f\'{NEW_DS_PATH}/images\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/images/val\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/train\')\n    os.mkdir(f\'{NEW_DS_PATH}/labels/val\')\n    \n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/train/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/train\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.jpg\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/images/val\')\n    for filepath in glob.glob(f\'{ORIGINAL_DS_PATH}/val/*.txt\'):\n        shutil.copy2(filepath, f\'{NEW_DS_PATH}/labels/val\')\n        \n    s = f\'path: {NEW_DS_PATH} \\n\'\n    s += \'train: ./images/train/ \\n\'\n    s += \'val: ./images/val/ \\n\'\n    s += \'names: \\n\'\n    s += \'  0: live \\n\'\n    s += \'  1: dead \\n\'\n    s += \'  2: vcut \\n\'\n    with open(f\'{NEW_DS_PATH}/dataset.yaml\', \'w\') as f:\n        f.write(s)', 'create_new_dataset': <function create_new_dataset at 0x74ce36169990>, '_i7': 'def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=["train", "val"]):\n    """ \n    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n    """ \n    dataset = fo.Dataset(name, persistent=True)\n    for split in splits:\n        dataset.add_dir(\n            dataset_dir=dataset_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            split=split,\n            tags=split,\n    )\n    return dataset', 'yolo2fiftyone': <function yolo2fiftyone at 0x74ce361696c0>, '_i8': 'def add_embeddings_field():\n    """ \n    """ \n    model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")\n    dataset.compute_embeddings(model=model, embeddings_field=\'embeddings\')', 'add_embeddings_field': <function add_embeddings_field at 0x74ce36169a20>, '_i9': 'def cosine_similarity(a, b):\n    return np.dot(a,b)/(norm(a)*norm(b))\n \n# a = np.array([2,1,2,3,2,9])\n# b = np.array([3,4,2,4,5,5])\n# cosine_similarity(a, b)', 'cosine_similarity': <function cosine_similarity at 0x74ce36169510>, '_i10': 'def add_similarity_with_prev_img_field():\n    """ \n    """\n    view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    # thresh = 0.92\n    first_sample = True\n    for sample in view:\n        if first_sample:\n            current_embeddings = sample.embeddings\n            similarity = 0.0\n            first_sample = False\n        else:\n            previous_embeddings = current_embeddings\n            current_embeddings = sample.embeddings\n            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n        sample[\'similarity_with_prev_img\'] = similarity\n        # if similarity > thresh:\n        #     sample.tags.append(f\'similarity>{thresh}\')\n        # else:\n        #     sample.tags.append(\'similarity OK\') \n        sample.save()', 'add_similarity_with_prev_img_field': <function add_similarity_with_prev_img_field at 0x74ce36169cf0>, '_i11': 'def add_predictions_field():\n    """ \n    """\n    # Load YOLOv8 model\n    # from ultralytics import YOLO\n    model = YOLO(ORIGINAL_MODEL_PATH)\n    dataset.apply_model(model, label_field="yolov8")\n    \n# add_predictions_field()', 'add_predictions_field': <function add_predictions_field at 0x74ce36168b80>, '_i12': 'def add_mistakenness_field():\n    """ \n    Adds mistakenness, possible_missing and possible_spurious fields.\n    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n    """\n    fob.compute_mistakenness(dataset, "yolov8", label_field="ground_truth")  \n    \n# add_mistakenness_field() ', 'add_mistakenness_field': <function add_mistakenness_field at 0x74ce36169c60>, '_i13': 'def add_field(fieldname, func):\n    """ \n    This utility function checks for existence of a field in a dataset.\n    If the field does not exist it is added by running func.\n    """\n    if dataset.get_field(fieldname):\n        logger.info(f\'"{fieldname}" field already exists\')\n    else:\n        logger.info(f\'Adding "{fieldname}" field\')\n        func()\n\n# def add_new_field():\n#     """ \n#     Code for adding a field named \'new\' should be inserted in this function.\n#     """\n#     pass\n    \n# add_field(\'new\', add_new_field)', 'add_field': <function add_field at 0x74ce36169f30>, '_i14': 'def create_autocorrelated_images_view(threshold, delete=False):\n    """ \n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    sorted_by_timestamp_view = dataset.load_saved_view(\'sorted_by_timestamp\')\n    view = sorted_by_timestamp_view.match(\n        F(\'similarity_with_prev_img\') > threshold)\n    dataset.save_view("autocorrelated_images_view", view, overwrite=True)\n    count = view.count()\n    \n    if delete:\n        dataset.delete_samples(view) \n        dataset.save()\n     \n    return count\n  \n# create_autocorrelated_images_view(0.98, True)', 'create_autocorrelated_images_view': <function create_autocorrelated_images_view at 0x74ce36169ea0>, '_i15': 'def count_ground_truth_bbs(dataset):\n    total_detections = 0\n    for sample in dataset:\n        total_detections += len(sample.ground_truth.detections)\n    return total_detections\n\n# count_ground_truth_bbs()', 'count_ground_truth_bbs': <function count_ground_truth_bbs at 0x74ce361693f0>, '_i16': 'def create_bb_touching_edge_view(delete=False):\n    """ \n    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n    """\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    view = dataset.filter_labels(\'ground_truth\', \n        (F(\'bounding_box\')[0] <= 0) | # left\n        (F(\'bounding_box\')[1] <= 0) | # top\n        ((F(\'bounding_box\')[0] + F(\'bounding_box\')[3]) >= 1) # right\n    )\n    dataset.save_view(\'bb_touching_edge\', view, overwrite=True) \n    count = view.count()\n           \n    if delete:\n        dataset.delete_labels(view)\n    dataset.save()\n            \n    return  count\n\n# create_bb_touching_edge_view()', 'create_bb_touching_edge_view': <function create_bb_touching_edge_view at 0x74ce36169120>, '_i17': 'def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n    """ \n    Removes unannoted images from a YOLO5 data set\n    Arguments:\n        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n    Returns:\n        count -- number of image (*.jpg) and annotation file pairs removed\n    """ \n    search_str = f\'{yolo5_dataset_path}/**/*.txt\'\n    txt_paths = glob.glob(search_str, recursive=True)\n    count = 0\n    for txt_path in txt_paths:\n        if os.path.getsize(txt_path) == 0:\n            img_path = txt_path.replace(\'labels\', \'images\').replace(\'.txt\', \'.jpg\')\n            os.remove(txt_path)\n            os.remove(img_path)\n            count += 1\n    return count\n\n# remove_unannotated_images(\n#     yolo5_dataset_path=\'/home/aubrey/myexport\')', 'remove_unannotated_images': <function remove_unannotated_images at 0x74ce36169fc0>, '_i18': 'def export_51_to_YOLO(dataset_name: str, \n                      export_dir: str, \n                      remove_unannotated: bool) -> int:\n    """\n    Export a dataset from 51 format to YOLO5 format.\n    Optionally, unannotated images will be removed from the export_dir.\n    \n    Arguments:\n    dataset_name -- a saved (persistent) 51 dataset\n    export_dir -- absolute destination path for the YOLO5 dataset\n    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n\n    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n    """\n    label_field = "ground_truth"\n\n    # The splits to export\n    splits = ["train", "val"]\n\n    # All splits must use the same classes list\n    classes = ["live", "dead", "vcut"]\n\n    # The dataset or view to export\n    # We assume the dataset uses sample tags to encode the splits to export\n    dataset_or_view = fo.load_dataset(dataset_name)\n\n    # Export the splits\n    for split in splits:\n        split_view = dataset_or_view.match_tags(split)\n        split_view.export(\n            export_dir=export_dir,\n            dataset_type=fo.types.YOLOv5Dataset,\n            label_field=label_field,\n            split=split,\n            classes=classes,\n        )\n        \n    # Remove unannotated images (optional)\n    images_removed = 0\n    if remove_unannotated:\n        images_removed = remove_unannotated_images(\n            yolo5_dataset_path=export_dir)\n    return images_removed     \n\n# export_51_to_YOLO(\n#     dataset_name=\'Guam07v3\', \n#     export_dir=\'/home/aubrey/myexport\', \n#     remove_unannotated=True)', 'export_51_to_YOLO': <function export_51_to_YOLO at 0x74ce3616a050>, '_i19': "def train_model():\n\n    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n    results = model.train(\n        resume = True,\n        imgsz=1920,\n        rect=True,\n        # data= '/home/aubrey/myexport/dataset.yaml',\n        epochs=5,\n        batch=-1,\n        patience=5,\n        name='newt'\n    )\n\n# train_model()\n \n# train model\n# !yolo \\\n# task=detect \\\n# mode=train \\\n# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n# imgsz=1920 \\\n# data= /home/aubrey/myexport/dataset.yaml \\\n# epochs=1000 \\\n# batch=-1 \\\n# patience=50 \\\n# name=dataset3_yolov8n", 'train_model': <function train_model at 0x74ce3616a0e0>, '_i20': 'def launch_cvat(anno_key_suffix: str, view) -> str:\n    """ \n    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n    \n    Arguments:\n    anno_key_suffix - string     \n    view - the view to be imported into CVAT\n    \n    Result:\n    \n    anno_key - a unique string in the form of myview-2024-11-27-16:57\n    """\n    timestamp = datetime.strftime(datetime.now(), \'%Y%m%d%H%M\')\n    anno_key = f\'{anno_key_suffix}_{timestamp}\'\n    view.annotate(\n        anno_key= anno_key,\n        label_field="ground_truth", \n        launch_editor=True\n    )\n    return anno_key\n    \n# random_dozen_view = dataset.take(12)\n# launch_cvat(\'random_dozen\', random_dozen_view)', 'launch_cvat': <function launch_cvat at 0x74ce3616a560>, '_i21': 'def configure_logger(LOGFILE):\n    """\n    Configure logger to send messages to notebook and LOGFILE\n    """\n    logging.root.handlers = []\n    logging.basicConfig(\n        level=logging.INFO, \n        format=\'%(asctime)s %(message)s\',\n        datefmt=\'%Y-%m-%d %H:%M:%S\',\n        handlers=[\n            logging.FileHandler(filename=LOGFILE),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    logger = logging.getLogger()\n    return logger', 'configure_logger': <function configure_logger at 0x74ce3616a4d0>, '_i22': '# MAIN\n\n# Start of constants #############################################################################\n\n# path to dataset in new YOLO format \nORIGINAL_DS_PATH = \'/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks\'\n\n# path to latest weights file\nORIGINAL_MODEL_PATH = f\'{ORIGINAL_DS_PATH}/runs/detect/train5/weights/best.pt\'\n\n# path to dataset in YOLOv5 format\nNEW_DS_PATH = \'/home/aubrey/datasets/Guam07v3\'\n\n# name of FiftyOne dataset\nFO_DATASET_NAME = \'Guam07v3\'\n\n# file name for log file saved in the same folder as this notebook\nLOGFILE = \'create_new_dataset.log\'\n\n# Arguments for create_autocorrelated_images_view function.\nAUTOCORRELATED_IMAGES_THRESHOLD = 0.98\nDELETE_AUTOCORRELATED_IMAGES = True\n\n# Argument for create_autocorrelated_images_view function\nDELETE_BBS_TOUCHING_EDGES = True\n\n# Option to retrain model. Usually FALSE.\nRETRAIN_MODEL = False\n\n# Option to launch FiftyOne in browser at end of workflow. Usually True.\nLAUNCH_51 = True\n\n# End of constants ########################################################################\n\n#configure logger\nlogger = configure_logger(LOGFILE)\n\nlogger.info(globals())\n\n# update requirements.txt\nlogger.info(\'Updating "requirements.txt"\')\nupdate_requirements_file()\n\n# wrangle dataset into YOLOv5 format\nif os.path.exists(NEW_DS_PATH):\n    logger.info(f\'"{NEW_DS_PATH}" already exists in YOLOv5 format\')\nelse:\n    logger.info(f\'creating dataset "{NEW_DS_PATH}" in YOLOv5 format\')\n    create_new_dataset(ORIGINAL_DS_PATH, NEW_DS_PATH)\n\n# Create new FiftyOne dataset\nif FO_DATASET_NAME in fo.list_datasets():\n    logger.info(f\'FiftyOne dataset "{FO_DATASET_NAME}" already exists\') \nelse:\n    logger.info(f\'Creating FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=NEW_DS_PATH)\n    \n# Load dataset\nlogger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\ndataset = fo.load_dataset(FO_DATASET_NAME)\nlogger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n# Add fields if they don\'t already exist\nadd_field(\'timestamp\', add_timestamp_field)\nadd_field(\'embeddings\', add_embeddings_field)\nadd_field(\'similarity_with_prev_img\', add_similarity_with_prev_img_field)\nadd_field(\'yolov8\', add_predictions_field)\nadd_field(\'mistakenness\', add_mistakenness_field)\n\n# Find bounding boxes touching left, top or right edges of images\nif \'bb_touching_edge\' in dataset.list_saved_views():\n    logger.info(\'"bb_touching_edge_view" already exists\')\nelse:\n    logger.info(\'Creating "bb_touching_edge_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is True; bbs will be deleted\')\n    else:\n        logger.info(\'    "DELETE_BBS_TOUCHING_EDGES" is False; bbs will not be deleted\')\n    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n    logger.info(f\'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found\')\n\n# Find autocorrelated images\nif \'autocorrelated_images_view\' in dataset.list_saved_views():\n    logger.info(\'"autocorrelated_images_view" already exists\')\nelse:\n    logger.info(\'Creating "autocorrelated_images_view"\')\n    if DELETE_BBS_TOUCHING_EDGES:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is True; samples will be deleted\')\n    else:\n        logger.info(\'    "DELETE_AUTOCORRELATED_IMAGES" is False; bbs will not be deleted\')\n    autocorrelated_image_count = create_autocorrelated_images_view(\n        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n    logger.info(f\'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found\')\n\nif RETRAIN_MODEL:\n    export_51_to_YOLO(\n        dataset_name=\'Guam07v3\', \n        export_dir=\'/home/aubrey/myexport\', \n        remove_unannotated=True)\n    train_model()\n\nif LAUNCH_51:\n    \n    # Reload dataset\n    logger.info(f\'Loading FiftyOne dataset "{FO_DATASET_NAME}"\')\n    dataset = fo.load_dataset(FO_DATASET_NAME)\n    logger.info(f\'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}\')\n\n    # Launch FiftyOne app in browser\n    logger.info(f\'Launching FifyOne app in browser\')\n    session = fo.launch_app(dataset, auto=False)\n    logger.info(session)\n\nlogger.info(\'FINISHED\')', 'ORIGINAL_DS_PATH': '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks', 'ORIGINAL_MODEL_PATH': '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt', 'NEW_DS_PATH': '/home/aubrey/datasets/Guam07v3', 'FO_DATASET_NAME': 'Guam07v3', 'LOGFILE': 'create_new_dataset.log', 'AUTOCORRELATED_IMAGES_THRESHOLD': 0.98, 'DELETE_AUTOCORRELATED_IMAGES': True, 'DELETE_BBS_TOUCHING_EDGES': True, 'RETRAIN_MODEL': False, 'LAUNCH_51': True, 'logger': <RootLogger root (INFO)>}
2024-11-27 17:41:07 Updating "requirements.txt"
2024-11-27 17:41:07 "/home/aubrey/datasets/Guam07v3" already exists in YOLOv5 format
2024-11-27 17:41:09 FiftyOne dataset "Guam07v3" already exists
2024-11-27 17:41:09 Loading FiftyOne dataset "Guam07v3"
2024-11-27 17:41:16     Ground truth bounding boxes: 14807
2024-11-27 17:41:16 "timestamp" field already exists
2024-11-27 17:41:16 "embeddings" field already exists
2024-11-27 17:41:16 "similarity_with_prev_img" field already exists
2024-11-27 17:41:16 "yolov8" field already exists
2024-11-27 17:41:16 "mistakenness" field already exists
2024-11-27 17:41:16 "bb_touching_edge_view" already exists
2024-11-27 17:41:16 "autocorrelated_images_view" already exists
2024-11-27 17:41:16 Loading FiftyOne dataset "Guam07v3"
2024-11-27 17:41:23     Ground truth bounding boxes: 14807
2024-11-27 17:41:23 Launching FifyOne app in browser
2024-11-27 17:41:25 Session launched. Run `session.show()` to open the App in a cell output.
2024-11-27 17:41:25 Dataset:          Guam07v3
Media type:       image
Num samples:      8959
Selected samples: 0
Selected labels:  0
Session URL:      http://localhost:5151/
2024-11-27 17:41:25 FINISHED
