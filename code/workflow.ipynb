{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create_new_dataset.ipynb\n",
    "\n",
    "This notebook implements my workflow for fine tuning a YOLOv8 object detection model which\n",
    "detects coconut rhinoceros beetle damage in coconut palms.\n",
    "\n",
    "# Installation\n",
    "\n",
    "Clone the repo\n",
    "```\n",
    "git clone https://github.com/aubreymoore/CRB-Damage-Dataset-Improvement\n",
    "```\n",
    "\n",
    "Move to the new folder\n",
    "```\n",
    "cd CRB-Damage-Dataset-Improvement\n",
    "```\n",
    "\n",
    "Create a virtual environment\n",
    "```\n",
    "python3 -m venv .venv\n",
    "```\n",
    "\n",
    "Activate the new virtual environment\n",
    "```\n",
    "source venv/bin/activate\n",
    "```\n",
    "\n",
    "Install required python modules\n",
    "```\n",
    "pip install -r code/requirements.txt\n",
    "```\n",
    "\n",
    "Create a .gitignore file and add .venv to the list of files and folders to be ignored.\n",
    "Adding a virtual environmant to a repository is bad practice.\n",
    "```\n",
    "echo \".venv\" >> .gitignore\n",
    "```\n",
    "\n",
    "# References\n",
    "\n",
    "https://pybit.es/articles/a-better-place-to-put-your-python-virtual-environments/\n",
    "\n",
    "[Image Deduplication](https://github.com/voxel51/fiftyone-examples/blob/master/examples/image_deduplication.ipynb)\n",
    "\n",
    "[CVAT <> FiftyOne: Data-Centric Machine Learning with Two Open Source Tools](https://www.cvat.ai/post/data-centric)\n",
    "\n",
    "[FiftyOne - Ultralytics Integration](https://docs.voxel51.com/integrations/ultralytics.html)\n",
    "\n",
    "[Finding Detection Mistakes with FiftyOne](https://docs.voxel51.com/tutorials/detection_mistakes.html)\n",
    "\n",
    "[Fine-tune YOLOv8 models for custom use cases with the help of FiftyOne](https://docs.voxel51.com/tutorials/yolov8.html)\n",
    "\n",
    "[FiftyOne Brain](https://docs.voxel51.com/brain.html)\n",
    "\n",
    "[Tracking Datasets in FiftyOne](https://voxel51.com/blog/tracking-datasets-in-fiftyone/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "import logging\n",
    "import sys\n",
    "from icecream import ic\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from ultralytics import YOLO\n",
    "import glob\n",
    "import ipywidgets as widgets\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timestamp_for_filename():\n",
    "    \"\"\" \n",
    "    Returns current time formated for use in creating a new file path.\n",
    "    Formatted as '%Y%m%d_%H%M'; Example: '20241129_1648'\n",
    "    \"\"\"\n",
    "    return datetime.strftime(datetime.now(), '%Y%m%d_%H%M')\n",
    "\n",
    "# create_timestamp_for_filename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_timestamp_field():\n",
    "    dataset.add_sample_field(\"timestamp\", fo.DateTimeField)\n",
    "\n",
    "    for sample in dataset:\n",
    "        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n",
    "        dt = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')\n",
    "        # ic(timestamp_str, dt)\n",
    "        sample['timestamp'] = dt\n",
    "        sample.save()\n",
    "    \n",
    "    # Create view  \n",
    "    view = dataset.sort_by(F'timestamp')\n",
    "    dataset.save_view('sorted_by_timestamp', view, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_requirements_file():\n",
    "    os.system('pip list --format=freeze > requirements.txt')\n",
    "\n",
    "# update_requirements_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_dataset(NONSTANDARD_DATASET_PATH, YOLO_DATASET_PATH):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    os.mkdir(YOLO_DATASET_PATH)\n",
    "    os.mkdir(f'{YOLO_DATASET_PATH}/images')\n",
    "    os.mkdir(f'{YOLO_DATASET_PATH}/images/train')\n",
    "    os.mkdir(f'{YOLO_DATASET_PATH}/images/val')\n",
    "    os.mkdir(f'{YOLO_DATASET_PATH}/labels')\n",
    "    os.mkdir(f'{YOLO_DATASET_PATH}/labels/train')\n",
    "    os.mkdir(f'{YOLO_DATASET_PATH}/labels/val')\n",
    "    \n",
    "    for filepath in glob.glob(f'{NONSTANDARD_DATASET_PATH}/train/*.jpg'):\n",
    "        shutil.copy2(filepath, f'{YOLO_DATASET_PATH}/images/train')\n",
    "    for filepath in glob.glob(f'{NONSTANDARD_DATASET_PATH}/train/*.txt'):\n",
    "        shutil.copy2(filepath, f'{YOLO_DATASET_PATH}/labels/train')\n",
    "    for filepath in glob.glob(f'{NONSTANDARD_DATASET_PATH}/val/*.jpg'):\n",
    "        shutil.copy2(filepath, f'{YOLO_DATASET_PATH}/images/val')\n",
    "    for filepath in glob.glob(f'{NONSTANDARD_DATASET_PATH}/val/*.txt'):\n",
    "        shutil.copy2(filepath, f'{YOLO_DATASET_PATH}/labels/val')\n",
    "        \n",
    "    s = f'path: {YOLO_DATASET_PATH} \\n'\n",
    "    s += 'train: ./images/train/ \\n'\n",
    "    s += 'val: ./images/val/ \\n'\n",
    "    s += 'names: \\n'\n",
    "    s += '  0: live \\n'\n",
    "    s += '  1: dead \\n'\n",
    "    s += '  2: vcut \\n'\n",
    "    with open(f'{YOLO_DATASET_PATH}/dataset.yaml', 'w') as f:\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo2fiftyone(name, dataset_dir, splits=[\"train\", \"val\"]):\n",
    "    \"\"\" \n",
    "    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split\n",
    "    \n",
    "    Arguments:\n",
    "        name - name of FiftyOne dataset to be created \n",
    "        dataset_dir - path to dataset in YOLOv5 format\n",
    "        splits - list of splits to be included   \n",
    "    \"\"\" \n",
    "    dataset = fo.Dataset(name, persistent=True)\n",
    "    for split in splits:\n",
    "        dataset.add_dir(\n",
    "            dataset_dir=dataset_dir,\n",
    "            dataset_type=fo.types.YOLOv5Dataset,\n",
    "            split=split,\n",
    "            tags=split,\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "# yolo2fiftyone(FO_DATASET_NAME, YOLO_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings_field():\n",
    "    \"\"\" \n",
    "    \"\"\" \n",
    "    model = foz.load_zoo_model(\"mobilenet-v2-imagenet-torch\")\n",
    "    dataset.compute_embeddings(model=model, embeddings_field='embeddings')\n",
    "    \n",
    "# add_embeddings_field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a,b)/(norm(a)*norm(b))\n",
    " \n",
    "# a = np.array([2,1,2,3,2,9])\n",
    "# b = np.array([3,4,2,4,5,5])\n",
    "# cosine_similarity(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_similarity_with_prev_img_field():\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    view = dataset.load_saved_view('sorted_by_timestamp')\n",
    "    # thresh = 0.92\n",
    "    first_sample = True\n",
    "    for sample in view:\n",
    "        if first_sample:\n",
    "            current_embeddings = sample.embeddings\n",
    "            similarity = 0.0\n",
    "            first_sample = False\n",
    "        else:\n",
    "            previous_embeddings = current_embeddings\n",
    "            current_embeddings = sample.embeddings\n",
    "            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n",
    "        sample['similarity_with_prev_img'] = similarity\n",
    "        # if similarity > thresh:\n",
    "        #     sample.tags.append(f'similarity>{thresh}')\n",
    "        # else:\n",
    "        #     sample.tags.append('similarity OK') \n",
    "        sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions_field():\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    # Load YOLOv8 model\n",
    "    # from ultralytics import YOLO\n",
    "    model = YOLO(WEIGHTS)\n",
    "    dataset.apply_model(model, label_field=\"yolov8\")\n",
    "    \n",
    "# add_predictions_field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mistakenness_field():\n",
    "    \"\"\" \n",
    "    Adds mistakenness, possible_missing and possible_spurious fields.\n",
    "    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n",
    "    \"\"\"\n",
    "    fob.compute_mistakenness(dataset, \"yolov8\", label_field=\"ground_truth\")  \n",
    "    \n",
    "# add_mistakenness_field() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_field(fieldname, func):\n",
    "    \"\"\" \n",
    "    This utility function checks for existence of a field in a dataset.\n",
    "    If the field does not exist it is added by running func.\n",
    "    \"\"\"\n",
    "    if dataset.get_field(fieldname):\n",
    "        logger.info(f'\"{fieldname}\" field already exists')\n",
    "    else:\n",
    "        logger.info(f'Adding \"{fieldname}\" field')\n",
    "        func()\n",
    "\n",
    "# def add_new_field():\n",
    "#     \"\"\" \n",
    "#     Code for adding a field named 'new' should be inserted in this function.\n",
    "#     \"\"\"\n",
    "#     pass\n",
    "    \n",
    "# add_field('new', add_new_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autocorrelated_images_view(threshold, delete=False):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    dataset = fo.load_dataset(FO_DATASET_NAME)\n",
    "    sorted_by_timestamp_view = dataset.load_saved_view('sorted_by_timestamp')\n",
    "    view = sorted_by_timestamp_view.match(\n",
    "        F('similarity_with_prev_img') > threshold)\n",
    "    dataset.save_view(\"autocorrelated_images_view\", view, overwrite=True)\n",
    "    count = view.count()\n",
    "    \n",
    "    if delete:\n",
    "        dataset.delete_samples(view) \n",
    "        dataset.save()\n",
    "     \n",
    "    return count\n",
    "  \n",
    "# create_autocorrelated_images_view(0.98, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ground_truth_bbs(dataset):\n",
    "    total_detections = 0\n",
    "    for sample in dataset:\n",
    "        total_detections += len(sample.ground_truth.detections)\n",
    "    return total_detections\n",
    "\n",
    "# count_ground_truth_bbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bb_touching_edge_view(delete=False):\n",
    "    \"\"\" \n",
    "    Find, tag and optionally delete ground truth bounding boxes which are touching\n",
    "    or almost touching the left, top or right edge of the image.    \n",
    "    \n",
    "    Reference:\n",
    "        https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n",
    "    \"\"\"\n",
    "    dataset = fo.load_dataset(FO_DATASET_NAME)\n",
    "    view = dataset.filter_labels('ground_truth', \n",
    "        (F('bounding_box')[0] <= 0.001) | # left\n",
    "        (F('bounding_box')[1] <= 0.001) | # top\n",
    "        ((F('bounding_box')[0] + F('bounding_box')[3]) >= 0.999) # right\n",
    "    )\n",
    "    count = view.count()\n",
    "    view.tag_labels('bb touching edge')   \n",
    "    dataset.save_view('bb_touching_edge', view, overwrite=True) \n",
    "            \n",
    "    if delete:\n",
    "        dataset.delete_labels(tags=\"bb touching edge\")\n",
    "         \n",
    "    dataset.save()\n",
    "            \n",
    "    return  count\n",
    "\n",
    "# create_bb_touching_edge_view(delete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n",
    "    \"\"\" \n",
    "    Removes unannoted images from a YOLO5 data set\n",
    "    Arguments:\n",
    "        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n",
    "    Returns:\n",
    "        count -- number of image (*.jpg) and annotation file pairs removed\n",
    "    \"\"\" \n",
    "    search_str = f'{yolo5_dataset_path}/**/*.txt'\n",
    "    txt_paths = glob.glob(search_str, recursive=True)\n",
    "    count = 0\n",
    "    for txt_path in txt_paths:\n",
    "        if os.path.getsize(txt_path) == 0:\n",
    "            img_path = txt_path.replace('labels', 'images').replace('.txt', '.jpg')\n",
    "            os.remove(txt_path)\n",
    "            os.remove(img_path)\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# remove_unannotated_images(\n",
    "#     yolo5_dataset_path='/home/aubrey/myexport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_51_to_YOLO(dataset_name: str, \n",
    "                      export_dir: str, \n",
    "                      remove_unannotated: bool) -> int:\n",
    "    \"\"\"\n",
    "    Export a dataset from 51 format to YOLO5 format.\n",
    "    Optionally, unannotated images will be removed from the export_dir.\n",
    "    \n",
    "    Arguments:\n",
    "    dataset_name -- a saved (persistent) 51 dataset (the dataset to be exported)\n",
    "    export_dir -- absolute destination path for the YOLO5 dataset. Should be given a new dataset name.\n",
    "    remove_unannoted -- if True, unannotated images (images containing no detected objects) are removed from the new YOLO5 dataset\n",
    "\n",
    "    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n",
    "    \"\"\"\n",
    "    label_field = \"ground_truth\"\n",
    "\n",
    "    # The splits to export\n",
    "    splits = [\"train\", \"val\"]\n",
    "\n",
    "    # All splits must use the same classes list\n",
    "    classes = [\"live\", \"dead\", \"vcut\"]\n",
    "\n",
    "    # The dataset or view to export\n",
    "    # We assume the dataset uses sample tags to encode the splits to export\n",
    "    dataset_or_view = fo.load_dataset(dataset_name)\n",
    "\n",
    "    # Export the splits\n",
    "    for split in splits:\n",
    "        split_view = dataset_or_view.match_tags(split)\n",
    "        split_view.export(\n",
    "            export_dir=export_dir,\n",
    "            dataset_type=fo.types.YOLOv5Dataset,\n",
    "            label_field=label_field,\n",
    "            split=split,\n",
    "            classes=classes,\n",
    "        )\n",
    "        \n",
    "    # Remove unannotated images (optional)\n",
    "    images_removed = 0\n",
    "    if remove_unannotated:\n",
    "        images_removed = remove_unannotated_images(\n",
    "            yolo5_dataset_path=export_dir)\n",
    "    return images_removed     \n",
    "\n",
    "# export_51_to_YOLO(\n",
    "#     dataset_name='Guam07v4', \n",
    "#     export_dir='/home/aubrey/crb_damage_detector_data/datasets/Guam07v5', \n",
    "#     remove_unannotated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(yaml_path):\n",
    "    model = YOLO()\n",
    "    results = model.train(\n",
    "        data = yaml_path,\n",
    "        imgsz=1920,\n",
    "        rect=True,\n",
    "        epochs=1000,\n",
    "        batch=-1,\n",
    "        patience=50,\n",
    "        name='yolo11n.pt'\n",
    "    )\n",
    "\n",
    "# train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_cvat(anno_key_suffix: str, view) -> str:\n",
    "    \"\"\" \n",
    "    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n",
    "    \n",
    "    Arguments:\n",
    "    anno_key_suffix - string     \n",
    "    view - the view to be imported into CVAT\n",
    "    \n",
    "    Result:\n",
    "    \n",
    "    anno_key - a unique string in the form of myview-2024-11-27-16:57\n",
    "    \"\"\"\n",
    "    timestamp = datetime.strftime(datetime.now(), '%Y%m%d%H%M')\n",
    "    anno_key = f'{anno_key_suffix}_{timestamp}'\n",
    "    view.annotate(\n",
    "        anno_key= anno_key,\n",
    "        label_field=\"ground_truth\", \n",
    "        launch_editor=True\n",
    "    )\n",
    "    return anno_key\n",
    "    \n",
    "# random_dozen_view = dataset.take(12)\n",
    "# launch_cvat('random_dozen', random_dozen_view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logger(LOGFILE):\n",
    "    \"\"\"\n",
    "    Configure logger to send messages to notebook and LOGFILE\n",
    "    \"\"\"\n",
    "    logging.root.handlers = []\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO, \n",
    "        format='%(asctime)s %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "            logging.FileHandler(filename=LOGFILE),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    "    logger = logging.getLogger()\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_weights_path():\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    search_str = f'{DATAPATH}/runs/[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]_[0-9][0-9][0-9][0-9]'\n",
    "    runs_list = glob.glob(search_str)\n",
    "    latest_run = sorted(runs_list, reverse=True)[0]\n",
    "    latest_weights_path = f'{latest_run}/weights/best.pt'\n",
    "    return latest_weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_yaml_path():\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    search_str = f'{DATAPATH}/datasets/[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]_[0-9][0-9][0-9][0-9]'\n",
    "    datasets_list = glob.glob(search_str)\n",
    "    latest_dataset = sorted(datasets_list, reverse=True)[0]\n",
    "    latest_yaml_path = f'{latest_dataset}/dataset.yaml'\n",
    "    return latest_yaml_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_51_dataset():\n",
    "    \"\"\" \n",
    "    Returns latest FiftyOne dataset which is named with a time stamp like '20241203_1148'\n",
    "    \"\"\"\n",
    "    datasets = []\n",
    "    for ds in fo.list_datasets():\n",
    "        if ds[0:7].isnumeric() and ds[8]=='_' and ds[9:12].isnumeric: \n",
    "            datasets.append(ds)\n",
    "    latest_51_dataset = sorted(datasets, reverse=True)[0]\n",
    "    return latest_51_dataset\n",
    "\n",
    "# get_latest_51_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model():\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    model = YOLO(latest_weights_path)\n",
    "    results = model.train(\n",
    "            data=latest_yaml_path,\n",
    "            imgsz=1920,\n",
    "            rect=True,\n",
    "            epochs=1000,\n",
    "            batch=-1,\n",
    "            patience=200,\n",
    "            save_dir=f'{DATAPATH}/runs',\n",
    "            name=create_timestamp_for_filename()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({}, {})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delete_tagged_bounding_boxes(dataset_name):\n",
    "    \"\"\" \n",
    "    Deletes labels (bounding boxes) that are tagged with 'delete'\n",
    "    \"\"\"\n",
    "    dataset = fo.load_dataset(dataset_name)\n",
    "    count_before = dataset.count_label_tags()\n",
    "    dataset.delete_labels(tags='delete')\n",
    "    count_after = dataset.count_label_tags()\n",
    "    dataset.save()\n",
    "    return count_before, count_after\n",
    "\n",
    "dataset_name = get_latest_51_dataset()    \n",
    "delete_tagged_bounding_boxes(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "if YOLO_DATASET_PATH exists:\n",
    "    continue\n",
    "else:\n",
    "    create_new_dataset(NONSTANDARD_DATASET_PATH, YOLO_DATASET_PATH)\n",
    "\n",
    "if FO_DATASET_NAME exists:\n",
    "    continue\n",
    "else:\n",
    "    yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=YOLO_DATASET_PATH)\n",
    "    \n",
    "dataset = fo.load_dataset(FO_DATASET_NAME)\n",
    "\n",
    "# Add sample fields if they don't already exist\n",
    "add_field('timestamp', add_timestamp_field)\n",
    "add_field('embeddings', add_embeddings_field)\n",
    "add_field('similarity_with_prev_img', add_similarity_with_prev_img_field)\n",
    "add_field('yolov8', add_predictions_field)\n",
    "add_field('mistakenness', add_mistakenness_field)\n",
    "\n",
    "if 'bb_touching_edge' in dataset.list_saved_views():\n",
    "    continue\n",
    "else:\n",
    "    create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n",
    "\n",
    "if 'autocorrelated_images_view' in dataset.list_saved_views():\n",
    "    continue\n",
    "else:\n",
    "    create_autocorrelated_images_view(AUTOCORRELATED_IMAGES_THRESHOLD, DELETE_AUTOCORRELATED_IMAGES)\n",
    "\n",
    "if RETRAIN_MODEL:\n",
    "    export_51_to_YOLO()\n",
    "    train_model()\n",
    "else:\n",
    "    continue\n",
    "\n",
    "if LAUNCH_51:\n",
    "    dataset = fo.load_dataset(FO_DATASET_NAME)\n",
    "    session = fo.launch_app(dataset, auto=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MAIN\n",
    "\n",
    "# # Start of constants #############################################################################\n",
    "\n",
    "# DATAPATH = '/home/aubrey/crb_damage_detector_data'\n",
    "\n",
    "# # path to dataset nonstandard format (images and labels in same folders). Not normally used.\n",
    "# NONSTANDARD_DATASET_PATH = None\n",
    "\n",
    "# # path to latest dataset in YOLOv5 format\n",
    "# YOLO_DATASET_PATH = '/home/aubrey/crb_damage_detector_data/datasets/20241128_1648'\n",
    "\n",
    "# # path to latest weights file\n",
    "# WEIGHTS = '/home/aubrey/crb_damage_detector_data/runs/20241128_1657/weights/best.pt'\n",
    "\n",
    "# # name of FiftyOne dataset\n",
    "# FO_DATASET_NAME = '20241128_1648'\n",
    "\n",
    "# # file name for log file saved in the same folder as this notebook\n",
    "# LOGFILE = f'{FO_DATASET_NAME}.log'\n",
    "\n",
    "# # Arguments for create_autocorrelated_images_view function.\n",
    "# AUTOCORRELATED_IMAGES_THRESHOLD = 0.98\n",
    "# DELETE_AUTOCORRELATED_IMAGES = True\n",
    "\n",
    "# # Argument for create_autocorrelated_images_view function\n",
    "# DELETE_BBS_TOUCHING_EDGES = True\n",
    "\n",
    "# # Option to retrain model. Usually FALSE.\n",
    "# RETRAIN_MODEL = False\n",
    "\n",
    "# # Option to launch the FiftyOne app in a browser at end of workflow. Usually True.\n",
    "# LAUNCH_51 = True\n",
    "\n",
    "# # End of constants ########################################################################\n",
    "\n",
    "# #configure logger\n",
    "# logger = configure_logger(LOGFILE)\n",
    "\n",
    "# # update requirements.txt\n",
    "# logger.info('Updating \"requirements.txt\"')\n",
    "# update_requirements_file()\n",
    "\n",
    "# # # wrangle dataset into YOLOv5 format\n",
    "# # if os.path.exists(YOLO_DATASET_PATH):\n",
    "# #     logger.info(f'\"{YOLO_DATASET_PATH}\" already exists in YOLOv5 format')\n",
    "# # else:\n",
    "# #     logger.info(f'creating dataset \"{YOLO_DATASET_PATH}\" in YOLOv5 format')\n",
    "# #     create_new_dataset(NONSTANDARD_DATASET_PATH, YOLO_DATASET_PATH)\n",
    "\n",
    "# # Create new FiftyOne dataset\n",
    "# if FO_DATASET_NAME in fo.list_datasets():\n",
    "#     logger.info(f'FiftyOne dataset \"{FO_DATASET_NAME}\" already exists') \n",
    "# else:\n",
    "#     logger.info(f'Creating FiftyOne dataset \"{FO_DATASET_NAME}\"')\n",
    "#     dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=YOLO_DATASET_PATH)\n",
    "    \n",
    "# # Load dataset\n",
    "# logger.info(f'Loading FiftyOne dataset \"{FO_DATASET_NAME}\"')\n",
    "# dataset = fo.load_dataset(FO_DATASET_NAME)\n",
    "# logger.info(f'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}')\n",
    "\n",
    "# # Add fields if they don't already exist\n",
    "# add_field('timestamp', add_timestamp_field)\n",
    "# add_field('embeddings', add_embeddings_field)\n",
    "# add_field('similarity_with_prev_img', add_similarity_with_prev_img_field)\n",
    "# add_field('yolov8', add_predictions_field)\n",
    "# add_field('mistakenness', add_mistakenness_field)\n",
    "\n",
    "# # Find bounding boxes touching left, top or right edges of images\n",
    "# if 'bb_touching_edge' in dataset.list_saved_views():\n",
    "#     logger.info('\"bb_touching_edge_view\" already exists')\n",
    "# else:\n",
    "#     logger.info('Creating \"bb_touching_edge_view\"')\n",
    "#     if DELETE_BBS_TOUCHING_EDGES:\n",
    "#         logger.info('    \"DELETE_BBS_TOUCHING_EDGES\" is True; bbs will be deleted')\n",
    "#     else:\n",
    "#         logger.info('    \"DELETE_BBS_TOUCHING_EDGES\" is False; bbs will not be deleted')\n",
    "#     bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n",
    "#     logger.info(f'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found')\n",
    "\n",
    "# # Find autocorrelated images\n",
    "# if 'autocorrelated_images_view' in dataset.list_saved_views():\n",
    "#     logger.info('\"autocorrelated_images_view\" already exists')\n",
    "# else:\n",
    "#     logger.info('Creating \"autocorrelated_images_view\"')\n",
    "#     if DELETE_BBS_TOUCHING_EDGES:\n",
    "#         logger.info('    \"DELETE_AUTOCORRELATED_IMAGES\" is True; samples will be deleted')\n",
    "#     else:\n",
    "#         logger.info('    \"DELETE_AUTOCORRELATED_IMAGES\" is False; bbs will not be deleted')\n",
    "#     autocorrelated_image_count = create_autocorrelated_images_view(\n",
    "#         threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n",
    "#     logger.info(f'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found')\n",
    "\n",
    "# if RETRAIN_MODEL:\n",
    "#     export_51_to_YOLO(\n",
    "#         dataset_name='Guam07v3', \n",
    "#         export_dir='/home/aubrey/myexport', \n",
    "#         remove_unannotated=True)\n",
    "#     train_model()\n",
    "\n",
    "# if LAUNCH_51:\n",
    "    \n",
    "#     # Reload dataset\n",
    "#     logger.info(f'Loading FiftyOne dataset \"{FO_DATASET_NAME}\"')\n",
    "#     dataset = fo.load_dataset(FO_DATASET_NAME)\n",
    "#     logger.info(f'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}')\n",
    "\n",
    "#     # Launch FiftyOne app in browser\n",
    "#     logger.info(f'Launching FifyOne app in browser')\n",
    "#     session = fo.launch_app(dataset, auto=False)\n",
    "#     logger.info(session)\n",
    "\n",
    "# logger.info('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_with_cvat(saved_view: str):\n",
    "    \"\"\" \n",
    "    Create annotation tasks for images in view\n",
    "    Reference: https://docs.voxel51.com/user_guide/annotation.html\n",
    "    The CVAT app should appear, loaded with images to be annotated.\n",
    "    When finished with annotations, merge back into the 51 dataset using \n",
    "    merge_cvat_annotations().\n",
    "    \"\"\"\n",
    "    anno_key = \"x\"\n",
    "    view = dataset.load_saved_view(saved_view)\n",
    "    view = dataset.filter_labels(\"ground_truth\", F(\"mistakenness\") > 0.338)\n",
    "    view.annotate(anno_key, label_field=\"ground_truth\", launch_editor=True)\n",
    "    # print(dataset.get_annotation_info(anno_key))\n",
    "  \n",
    "# annotate_with_cvat('mistakenness > 0.338')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_cvat_annotations():\n",
    "    \"\"\"\n",
    "    Merge the annotations back into FiftyOne\n",
    "    Reference: https://docs.voxel51.com/user_guide/annotation.html\n",
    "    \"\"\"\n",
    "    anno_key = \"x\"\n",
    "    dataset.load_annotations(anno_key)\n",
    "\n",
    "    # Load the view that was annotated in the App\n",
    "    view = dataset.load_annotation_view(anno_key)\n",
    "    session = fo.launch_app(view=view, auto=False)\n",
    "\n",
    "    # Cleanup\n",
    "\n",
    "    # Delete tasks from CVAT\n",
    "    results = dataset.load_annotation_results(anno_key)\n",
    "    results.cleanup()\n",
    "\n",
    "    # Delete run record (not the labels) from FiftyOne\n",
    "    dataset.delete_annotation_run(anno_key)\n",
    "    \n",
    "# merge_cvat_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mistakenness_338_view():\n",
    "    view = dataset.match(F(\"mistakenness\") > 0.338)\n",
    "    dataset.save_view('mistakenness > 0.338', view, overwrite=True) \n",
    "\n",
    "# create_mistakenness_338_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-03 17:34:47 Updating \"requirements.txt\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cb567125b54829978084847e011d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='import latest yolo dataset into 51', style=ButtonStyle()), Button(descriptiâ€¦"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "## CONSTANTS\n",
    "\n",
    "DATAPATH = '/home/aubrey/crb_damage_detector_data'\n",
    "\n",
    "# path to dataset nonstandard format (images and labels in same folders). Not normally used.\n",
    "NONSTANDARD_DATASET_PATH = None\n",
    "\n",
    "# path to latest dataset in YOLOv5 format\n",
    "YOLO_DATASET_PATH = '/home/aubrey/crb_damage_detector_data/datasets/20241128_1648'\n",
    "\n",
    "# path to latest weights file\n",
    "WEIGHTS = '/home/aubrey/crb_damage_detector_data/runs/20241128_1657/weights/best.pt'\n",
    "\n",
    "# name of FiftyOne dataset\n",
    "FO_DATASET_NAME = '20241128_1648'\n",
    "\n",
    "# file name for log file saved in the same folder as this notebook\n",
    "LOGFILE = f'{FO_DATASET_NAME}.log'\n",
    "\n",
    "# Arguments for create_autocorrelated_images_view function.\n",
    "AUTOCORRELATED_IMAGES_THRESHOLD = 0.98\n",
    "DELETE_AUTOCORRELATED_IMAGES = True\n",
    "\n",
    "# Argument for create_autocorrelated_images_view function\n",
    "DELETE_BBS_TOUCHING_EDGES = True\n",
    "\n",
    "# Option to retrain model. Usually FALSE.\n",
    "RETRAIN_MODEL = False\n",
    "\n",
    "# Option to launch the FiftyOne app in a browser at end of workflow. Usually True.\n",
    "LAUNCH_51 = True\n",
    "\n",
    "## CONFIGURE LOGGER\n",
    "logger = configure_logger(LOGFILE)\n",
    "\n",
    "## update requirements.txt\n",
    "logger.info('Updating \"requirements.txt\"')\n",
    "update_requirements_file()\n",
    "\n",
    "# CONTROL PANEL\n",
    "\n",
    "## Buttons\n",
    "btn_descriptions = [\n",
    "    'import latest yolo dataset into 51', \n",
    "    'Launch 51 in browser', \n",
    "    'add embeddings',\n",
    "    'export_51_to_YOLO',\n",
    "    'train_model'\n",
    "]\n",
    "\n",
    "## Callback function\n",
    "def on_button_clicked(b):\n",
    "    \"\"\" \n",
    "    To provide a visual indication of status, button sttyle is changed to 'primary' when clicked and 'success' when execution ends.\n",
    "    After a button is clicked, all buttons are disabled. All buttons are enabled when execution ends.\n",
    "    \"\"\"\n",
    "    for button in buttons:\n",
    "        button.disabled = True\n",
    "    b.button_style = 'primary' \n",
    "    match b.description:\n",
    "        case 'import latest yolo dataset into 51':\n",
    "            latest_yaml_path = get_latest_yaml_path()\n",
    "            name = create_timestamp_for_filename()\n",
    "            basename = os.path.basename(latest_yaml_path)\n",
    "            dataset_dir = latest_yaml_path.replace(f'/{basename}', '')\n",
    "            logger.info(f'Executing yolo2fiftyone() with the following parameters:')\n",
    "            logger.info(f'   name={name}')\n",
    "            logger.info(f'   dataset_dir={dataset_dir}')\n",
    "            logger.info(f'   splits=[\"train\", \"val\"])')\n",
    "            yolo2fiftyone(name=name, dataset_dir=dataset_dir, splits=[\"train\", \"val\"])\n",
    "        case 'Launch 51 in browser':     \n",
    "            logger.info(f'Launching FifyOne app in browser')\n",
    "            dataset = fo.load_dataset(name = get_latest_51_dataset())\n",
    "            session = fo.launch_app(dataset=dataset, auto=False)\n",
    "            logger.info(session)\n",
    "        case 'add embeddings': \n",
    "            logger.info('add_embeddings_field()')\n",
    "            add_embeddings_field()\n",
    "        case 'export_51_to_YOLO':\n",
    "            dataset_name = get_latest_51_dataset()\n",
    "            export_dir = f'{DATAPATH}/dataset/{create_timestamp_for_filename()}'\n",
    "            remove_unannotated = True\n",
    "            logger.info(f'Executing export_51_to_yolo() with the following parameters:')\n",
    "            logger.info(f'   dataset_name={dataset_name}')\n",
    "            logger.info(f'   export_dir={export_dir}')\n",
    "            logger.info(f'   remove_unannotated={remove_unannotated}')\n",
    "            export_51_to_YOLO(\n",
    "                dataset_name=dataset_name, \n",
    "                export_dir=export_dir, \n",
    "                remove_unannotated=remove_unannotated) \n",
    "        case 'train_model':\n",
    "            yaml_path = latest_yaml_path()\n",
    "            train_model(yaml_path=yaml_path) \n",
    "            logger.info(f'Executing train_model() with the following parameter:')\n",
    "            logger.info(f'   yaml_path={yaml_path}')         \n",
    "        case _: \n",
    "            print('--- not a valid b.description')           \n",
    "    b.button_style = 'success'\n",
    "    for button in buttons:\n",
    "        button.disabled = False\n",
    "\n",
    "# Widget layout\n",
    "buttons = []\n",
    "for i, btn_description in enumerate(btn_descriptions):\n",
    "    buttons.append(widgets.Button(description=f'{btn_descriptions[i]}'))   \n",
    "for button in buttons:\n",
    "    button.on_click(on_button_clicked)\n",
    "widgets.HBox(buttons)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
