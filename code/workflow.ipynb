{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create_new_dataset.ipynb\n",
    "\n",
    "This notebook implements my workflow for fine tuning a YOLOv8 object detection model which\n",
    "detects coconut rhinoceros beetle damage in coconut palms.\n",
    "\n",
    "# Installation\n",
    "\n",
    "Clone the repo\n",
    "```\n",
    "git clone https://github.com/aubreymoore/CRB-Damage-Dataset-Improvement\n",
    "```\n",
    "\n",
    "Move to the new folder\n",
    "```\n",
    "cd CRB-Damage-Dataset-Improvement\n",
    "```\n",
    "\n",
    "Create a virtual environment\n",
    "```\n",
    "python3 -m venv .venv\n",
    "```\n",
    "\n",
    "Activate the new virtual environment\n",
    "```\n",
    "source venv/bin/activate\n",
    "```\n",
    "\n",
    "Install required python modules\n",
    "```\n",
    "pip install -r code/requirements.txt\n",
    "```\n",
    "\n",
    "Create a .gitignore file and add .venv to the list of files and folders to be ignored.\n",
    "Adding a virtual environmant to a repository is bad practice.\n",
    "```\n",
    "echo \".venv\" >> .gitignore\n",
    "```\n",
    "\n",
    "# References\n",
    "\n",
    "https://pybit.es/articles/a-better-place-to-put-your-python-virtual-environments/\n",
    "\n",
    "[Image Deduplication](https://github.com/voxel51/fiftyone-examples/blob/master/examples/image_deduplication.ipynb)\n",
    "\n",
    "[CVAT <> FiftyOne: Data-Centric Machine Learning with Two Open Source Tools](https://www.cvat.ai/post/data-centric)\n",
    "\n",
    "[FiftyOne - Ultralytics Integration](https://docs.voxel51.com/integrations/ultralytics.html)\n",
    "\n",
    "[Finding Detection Mistakes with FiftyOne](https://docs.voxel51.com/tutorials/detection_mistakes.html)\n",
    "\n",
    "[Fine-tune YOLOv8 models for custom use cases with the help of FiftyOne](https://docs.voxel51.com/tutorials/yolov8.html)\n",
    "\n",
    "[FiftyOne Brain](https://docs.voxel51.com/brain.html)\n",
    "\n",
    "[Tracking Datasets in FiftyOne](https://voxel51.com/blog/tracking-datasets-in-fiftyone/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "import logging\n",
    "import sys\n",
    "from icecream import ic\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from ultralytics import YOLO\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_timestamp_field():\n",
    "    dataset.add_sample_field(\"timestamp\", fo.DateTimeField)\n",
    "\n",
    "    for sample in dataset:\n",
    "        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n",
    "        dt = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')\n",
    "        # ic(timestamp_str, dt)\n",
    "        sample['timestamp'] = dt\n",
    "        sample.save()\n",
    "    \n",
    "    # Create view  \n",
    "    view = dataset.sort_by(F'timestamp')\n",
    "    dataset.save_view('sorted_by_timestamp', view, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_requirements_file():\n",
    "    os.system('pip list --format=freeze > requirements.txt')\n",
    "\n",
    "# update_requirements_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_dataset(NONSTANDARD_DATASET_PATH, YOLO_DATASET_PATH):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    os.mkdir(YOLO_DATASET_PATH)\n",
    "    os.mkdir(f'{YOLO_DATASET_PATH}/images')\n",
    "    os.mkdir(f'{YOLO_DATASET_PATH}/images/train')\n",
    "    os.mkdir(f'{YOLO_DATASET_PATH}/images/val')\n",
    "    os.mkdir(f'{YOLO_DATASET_PATH}/labels')\n",
    "    os.mkdir(f'{YOLO_DATASET_PATH}/labels/train')\n",
    "    os.mkdir(f'{YOLO_DATASET_PATH}/labels/val')\n",
    "    \n",
    "    for filepath in glob.glob(f'{NONSTANDARD_DATASET_PATH}/train/*.jpg'):\n",
    "        shutil.copy2(filepath, f'{YOLO_DATASET_PATH}/images/train')\n",
    "    for filepath in glob.glob(f'{NONSTANDARD_DATASET_PATH}/train/*.txt'):\n",
    "        shutil.copy2(filepath, f'{YOLO_DATASET_PATH}/labels/train')\n",
    "    for filepath in glob.glob(f'{NONSTANDARD_DATASET_PATH}/val/*.jpg'):\n",
    "        shutil.copy2(filepath, f'{YOLO_DATASET_PATH}/images/val')\n",
    "    for filepath in glob.glob(f'{NONSTANDARD_DATASET_PATH}/val/*.txt'):\n",
    "        shutil.copy2(filepath, f'{YOLO_DATASET_PATH}/labels/val')\n",
    "        \n",
    "    s = f'path: {YOLO_DATASET_PATH} \\n'\n",
    "    s += 'train: ./images/train/ \\n'\n",
    "    s += 'val: ./images/val/ \\n'\n",
    "    s += 'names: \\n'\n",
    "    s += '  0: live \\n'\n",
    "    s += '  1: dead \\n'\n",
    "    s += '  2: vcut \\n'\n",
    "    with open(f'{YOLO_DATASET_PATH}/dataset.yaml', 'w') as f:\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo2fiftyone(FO_DATASET_NAME, dataset_dir, splits=[\"train\", \"val\"]):\n",
    "    \"\"\" \n",
    "    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n",
    "    \"\"\" \n",
    "    dataset = fo.Dataset(name, persistent=True)\n",
    "    for split in splits:\n",
    "        dataset.add_dir(\n",
    "            dataset_dir=dataset_dir,\n",
    "            dataset_type=fo.types.YOLOv5Dataset,\n",
    "            split=split,\n",
    "            tags=split,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings_field():\n",
    "    \"\"\" \n",
    "    \"\"\" \n",
    "    model = foz.load_zoo_model(\"mobilenet-v2-imagenet-torch\")\n",
    "    dataset.compute_embeddings(model=model, embeddings_field='embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a,b)/(norm(a)*norm(b))\n",
    " \n",
    "# a = np.array([2,1,2,3,2,9])\n",
    "# b = np.array([3,4,2,4,5,5])\n",
    "# cosine_similarity(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_similarity_with_prev_img_field():\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    view = dataset.load_saved_view('sorted_by_timestamp')\n",
    "    # thresh = 0.92\n",
    "    first_sample = True\n",
    "    for sample in view:\n",
    "        if first_sample:\n",
    "            current_embeddings = sample.embeddings\n",
    "            similarity = 0.0\n",
    "            first_sample = False\n",
    "        else:\n",
    "            previous_embeddings = current_embeddings\n",
    "            current_embeddings = sample.embeddings\n",
    "            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n",
    "        sample['similarity_with_prev_img'] = similarity\n",
    "        # if similarity > thresh:\n",
    "        #     sample.tags.append(f'similarity>{thresh}')\n",
    "        # else:\n",
    "        #     sample.tags.append('similarity OK') \n",
    "        sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions_field():\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    # Load YOLOv8 model\n",
    "    # from ultralytics import YOLO\n",
    "    model = YOLO(WEIGHTS)\n",
    "    dataset.apply_model(model, label_field=\"yolov8\")\n",
    "    \n",
    "# add_predictions_field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mistakenness_field():\n",
    "    \"\"\" \n",
    "    Adds mistakenness, possible_missing and possible_spurious fields.\n",
    "    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n",
    "    \"\"\"\n",
    "    fob.compute_mistakenness(dataset, \"yolov8\", label_field=\"ground_truth\")  \n",
    "    \n",
    "# add_mistakenness_field() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_field(fieldname, func):\n",
    "    \"\"\" \n",
    "    This utility function checks for existence of a field in a dataset.\n",
    "    If the field does not exist it is added by running func.\n",
    "    \"\"\"\n",
    "    if dataset.get_field(fieldname):\n",
    "        logger.info(f'\"{fieldname}\" field already exists')\n",
    "    else:\n",
    "        logger.info(f'Adding \"{fieldname}\" field')\n",
    "        func()\n",
    "\n",
    "# def add_new_field():\n",
    "#     \"\"\" \n",
    "#     Code for adding a field named 'new' should be inserted in this function.\n",
    "#     \"\"\"\n",
    "#     pass\n",
    "    \n",
    "# add_field('new', add_new_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autocorrelated_images_view(threshold, delete=False):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    dataset = fo.load_dataset(FO_DATASET_NAME)\n",
    "    sorted_by_timestamp_view = dataset.load_saved_view('sorted_by_timestamp')\n",
    "    view = sorted_by_timestamp_view.match(\n",
    "        F('similarity_with_prev_img') > threshold)\n",
    "    dataset.save_view(\"autocorrelated_images_view\", view, overwrite=True)\n",
    "    count = view.count()\n",
    "    \n",
    "    if delete:\n",
    "        dataset.delete_samples(view) \n",
    "        dataset.save()\n",
    "     \n",
    "    return count\n",
    "  \n",
    "# create_autocorrelated_images_view(0.98, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ground_truth_bbs(dataset):\n",
    "    total_detections = 0\n",
    "    for sample in dataset:\n",
    "        total_detections += len(sample.ground_truth.detections)\n",
    "    return total_detections\n",
    "\n",
    "# count_ground_truth_bbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bb_touching_edge_view(delete=False):\n",
    "    \"\"\" \n",
    "    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n",
    "    \"\"\"\n",
    "    dataset = fo.load_dataset(FO_DATASET_NAME)\n",
    "    view = dataset.filter_labels('ground_truth', \n",
    "        (F('bounding_box')[0] <= 0) | # left\n",
    "        (F('bounding_box')[1] <= 0) | # top\n",
    "        ((F('bounding_box')[0] + F('bounding_box')[3]) >= 1) # right\n",
    "    )\n",
    "    dataset.save_view('bb_touching_edge', view, overwrite=True) \n",
    "    count = view.count()\n",
    "           \n",
    "    if delete:\n",
    "        dataset.delete_labels(view)\n",
    "    dataset.save()\n",
    "            \n",
    "    return  count\n",
    "\n",
    "# create_bb_touching_edge_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unannotated_images(yolo5_dataset_path: str) -> int:\n",
    "    \"\"\" \n",
    "    Removes unannoted images from a YOLO5 data set\n",
    "    Arguments:\n",
    "        yolo5_dataset_path -- absolute path for the YOLO5 dataset\n",
    "    Returns:\n",
    "        count -- number of image (*.jpg) and annotation file pairs removed\n",
    "    \"\"\" \n",
    "    search_str = f'{yolo5_dataset_path}/**/*.txt'\n",
    "    txt_paths = glob.glob(search_str, recursive=True)\n",
    "    count = 0\n",
    "    for txt_path in txt_paths:\n",
    "        if os.path.getsize(txt_path) == 0:\n",
    "            img_path = txt_path.replace('labels', 'images').replace('.txt', '.jpg')\n",
    "            os.remove(txt_path)\n",
    "            os.remove(img_path)\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# remove_unannotated_images(\n",
    "#     yolo5_dataset_path='/home/aubrey/myexport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_51_to_YOLO(dataset_name: str, \n",
    "                      export_dir: str, \n",
    "                      remove_unannotated: bool) -> int:\n",
    "    \"\"\"\n",
    "    Export a dataset from 51 format to YOLO5 format.\n",
    "    Optionally, unannotated images will be removed from the export_dir.\n",
    "    \n",
    "    Arguments:\n",
    "    dataset_name -- a saved (persistent) 51 dataset\n",
    "    export_dir -- absolute destination path for the YOLO5 dataset\n",
    "    remove_unannoted -- if True, unannoted images are removed from the new YOLO5 dataset\n",
    "\n",
    "    Reference https://docs.voxel51.com/user_guide/export_datasets.html#yolov5dataset\n",
    "    \"\"\"\n",
    "    label_field = \"ground_truth\"\n",
    "\n",
    "    # The splits to export\n",
    "    splits = [\"train\", \"val\"]\n",
    "\n",
    "    # All splits must use the same classes list\n",
    "    classes = [\"live\", \"dead\", \"vcut\"]\n",
    "\n",
    "    # The dataset or view to export\n",
    "    # We assume the dataset uses sample tags to encode the splits to export\n",
    "    dataset_or_view = fo.load_dataset(dataset_name)\n",
    "\n",
    "    # Export the splits\n",
    "    for split in splits:\n",
    "        split_view = dataset_or_view.match_tags(split)\n",
    "        split_view.export(\n",
    "            export_dir=export_dir,\n",
    "            dataset_type=fo.types.YOLOv5Dataset,\n",
    "            label_field=label_field,\n",
    "            split=split,\n",
    "            classes=classes,\n",
    "        )\n",
    "        \n",
    "    # Remove unannotated images (optional)\n",
    "    images_removed = 0\n",
    "    if remove_unannotated:\n",
    "        images_removed = remove_unannotated_images(\n",
    "            yolo5_dataset_path=export_dir)\n",
    "    return images_removed     \n",
    "\n",
    "# export_51_to_YOLO(\n",
    "#     dataset_name='Guam07v3', \n",
    "#     export_dir='/home/aubrey/myexport', \n",
    "#     remove_unannotated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "\n",
    "    model = YOLO('/home/aubrey/label-studio-ml-backend/runs/detect/newt/weights/best.pt')\n",
    "    results = model.train(\n",
    "        resume = True,\n",
    "        imgsz=1920,\n",
    "        rect=True,\n",
    "        # data= '/home/aubrey/myexport/dataset.yaml',\n",
    "        epochs=5,\n",
    "        batch=-1,\n",
    "        patience=5,\n",
    "        name='newt'\n",
    "    )\n",
    "\n",
    "# train_model()\n",
    " \n",
    "# train model\n",
    "# !yolo \\\n",
    "# task=detect \\\n",
    "# mode=train \\\n",
    "# model= /home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks/runs/detect/train5/weights/best.pt \\\n",
    "# imgsz=1920 \\\n",
    "# data= /home/aubrey/myexport/dataset.yaml \\\n",
    "# epochs=1000 \\\n",
    "# batch=-1 \\\n",
    "# patience=50 \\\n",
    "# name=dataset3_yolov8n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_cvat(anno_key_suffix: str, view) -> str:\n",
    "    \"\"\" \n",
    "    Saves a FiftyOne view in CVAT and launches the CVAT annotator\n",
    "    \n",
    "    Arguments:\n",
    "    anno_key_suffix - string     \n",
    "    view - the view to be imported into CVAT\n",
    "    \n",
    "    Result:\n",
    "    \n",
    "    anno_key - a unique string in the form of myview-2024-11-27-16:57\n",
    "    \"\"\"\n",
    "    timestamp = datetime.strftime(datetime.now(), '%Y%m%d%H%M')\n",
    "    anno_key = f'{anno_key_suffix}_{timestamp}'\n",
    "    view.annotate(\n",
    "        anno_key= anno_key,\n",
    "        label_field=\"ground_truth\", \n",
    "        launch_editor=True\n",
    "    )\n",
    "    return anno_key\n",
    "    \n",
    "# random_dozen_view = dataset.take(12)\n",
    "# launch_cvat('random_dozen', random_dozen_view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logger(LOGFILE):\n",
    "    \"\"\"\n",
    "    Configure logger to send messages to notebook and LOGFILE\n",
    "    \"\"\"\n",
    "    logging.root.handlers = []\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO, \n",
    "        format='%(asctime)s %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "            logging.FileHandler(filename=LOGFILE),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    "    logger = logging.getLogger()\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "if YOLO_DATASET_PATH exists:\n",
    "    continue\n",
    "else:\n",
    "    create_new_dataset(NONSTANDARD_DATASET_PATH, YOLO_DATASET_PATH)\n",
    "\n",
    "if FO_DATASET_NAME exists:\n",
    "    continue\n",
    "else:\n",
    "    yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=YOLO_DATASET_PATH)\n",
    "    \n",
    "dataset = fo.load_dataset(FO_DATASET_NAME)\n",
    "\n",
    "# Add sample fields if they don't already exist\n",
    "add_field('timestamp', add_timestamp_field)\n",
    "add_field('embeddings', add_embeddings_field)\n",
    "add_field('similarity_with_prev_img', add_similarity_with_prev_img_field)\n",
    "add_field('yolov8', add_predictions_field)\n",
    "add_field('mistakenness', add_mistakenness_field)\n",
    "\n",
    "if 'bb_touching_edge' in dataset.list_saved_views():\n",
    "    continue\n",
    "else:\n",
    "    create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n",
    "\n",
    "if 'autocorrelated_images_view' in dataset.list_saved_views():\n",
    "    continue\n",
    "else:\n",
    "    create_autocorrelated_images_view(AUTOCORRELATED_IMAGES_THRESHOLD, DELETE_AUTOCORRELATED_IMAGES)\n",
    "\n",
    "if RETRAIN_MODEL:\n",
    "    export_51_to_YOLO()\n",
    "    train_model()\n",
    "else:\n",
    "    continue\n",
    "\n",
    "if LAUNCH_51:\n",
    "    dataset = fo.load_dataset(FO_DATASET_NAME)\n",
    "    session = fo.launch_app(dataset, auto=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "\n",
    "# Start of constants #############################################################################\n",
    "\n",
    "# path to dataset nonstandard format (images and labels in same folders). Not normally used.\n",
    "NONSTANDARD_DATASET_PATH = None\n",
    "\n",
    "# path to dataset in YOLOv5 format\n",
    "YOLO_DATASET_PATH = '/home/aubrey/crb_damage_detector_data/datasets/Guam07v4'\n",
    "\n",
    "# path to latest weights file\n",
    "WEIGHTS = '/home/aubrey/crb_damage_detector_data/runs/newt/weights/best.pt'\n",
    "\n",
    "# name of FiftyOne dataset\n",
    "FO_DATASET_NAME = 'Guam07v4'\n",
    "\n",
    "# file name for log file saved in the same folder as this notebook\n",
    "LOGFILE = 'Guam07v4.log'\n",
    "\n",
    "# Arguments for create_autocorrelated_images_view function.\n",
    "AUTOCORRELATED_IMAGES_THRESHOLD = 0.98\n",
    "DELETE_AUTOCORRELATED_IMAGES = True\n",
    "\n",
    "# Argument for create_autocorrelated_images_view function\n",
    "DELETE_BBS_TOUCHING_EDGES = True\n",
    "\n",
    "# Option to retrain model. Usually FALSE.\n",
    "RETRAIN_MODEL = False\n",
    "\n",
    "# Option to launch the FiftyOne app in a browser at end of workflow. Usually True.\n",
    "LAUNCH_51 = True\n",
    "\n",
    "# End of constants ########################################################################\n",
    "\n",
    "#configure logger\n",
    "logger = configure_logger(LOGFILE)\n",
    "\n",
    "logger.info(globals())\n",
    "\n",
    "# update requirements.txt\n",
    "logger.info('Updating \"requirements.txt\"')\n",
    "update_requirements_file()\n",
    "\n",
    "# wrangle dataset into YOLOv5 format\n",
    "if os.path.exists(YOLO_DATASET_PATH):\n",
    "    logger.info(f'\"{YOLO_DATASET_PATH}\" already exists in YOLOv5 format')\n",
    "else:\n",
    "    logger.info(f'creating dataset \"{YOLO_DATASET_PATH}\" in YOLOv5 format')\n",
    "    create_new_dataset(NONSTANDARD_DATASET_PATH, YOLO_DATASET_PATH)\n",
    "\n",
    "# Create new FiftyOne dataset\n",
    "if FO_DATASET_NAME in fo.list_datasets():\n",
    "    logger.info(f'FiftyOne dataset \"{FO_DATASET_NAME}\" already exists') \n",
    "else:\n",
    "    logger.info(f'Creating FiftyOne dataset \"{FO_DATASET_NAME}\"')\n",
    "    dataset = yolo2fiftyone(name=FO_DATASET_NAME, dataset_dir=YOLO_DATASET_PATH)\n",
    "    \n",
    "# Load dataset\n",
    "logger.info(f'Loading FiftyOne dataset \"{FO_DATASET_NAME}\"')\n",
    "dataset = fo.load_dataset(FO_DATASET_NAME)\n",
    "logger.info(f'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}')\n",
    "\n",
    "# Add fields if they don't already exist\n",
    "add_field('timestamp', add_timestamp_field)\n",
    "add_field('embeddings', add_embeddings_field)\n",
    "add_field('similarity_with_prev_img', add_similarity_with_prev_img_field)\n",
    "add_field('yolov8', add_predictions_field)\n",
    "add_field('mistakenness', add_mistakenness_field)\n",
    "\n",
    "# Find bounding boxes touching left, top or right edges of images\n",
    "if 'bb_touching_edge' in dataset.list_saved_views():\n",
    "    logger.info('\"bb_touching_edge_view\" already exists')\n",
    "else:\n",
    "    logger.info('Creating \"bb_touching_edge_view\"')\n",
    "    if DELETE_BBS_TOUCHING_EDGES:\n",
    "        logger.info('    \"DELETE_BBS_TOUCHING_EDGES\" is True; bbs will be deleted')\n",
    "    else:\n",
    "        logger.info('    \"DELETE_BBS_TOUCHING_EDGES\" is False; bbs will not be deleted')\n",
    "    bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n",
    "    logger.info(f'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found')\n",
    "\n",
    "# Find autocorrelated images\n",
    "if 'autocorrelated_images_view' in dataset.list_saved_views():\n",
    "    logger.info('\"autocorrelated_images_view\" already exists')\n",
    "else:\n",
    "    logger.info('Creating \"autocorrelated_images_view\"')\n",
    "    if DELETE_BBS_TOUCHING_EDGES:\n",
    "        logger.info('    \"DELETE_AUTOCORRELATED_IMAGES\" is True; samples will be deleted')\n",
    "    else:\n",
    "        logger.info('    \"DELETE_AUTOCORRELATED_IMAGES\" is False; bbs will not be deleted')\n",
    "    autocorrelated_image_count = create_autocorrelated_images_view(\n",
    "        threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n",
    "    logger.info(f'    With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found')\n",
    "\n",
    "if RETRAIN_MODEL:\n",
    "    export_51_to_YOLO(\n",
    "        dataset_name='Guam07v3', \n",
    "        export_dir='/home/aubrey/myexport', \n",
    "        remove_unannotated=True)\n",
    "    train_model()\n",
    "\n",
    "if LAUNCH_51:\n",
    "    \n",
    "    # Reload dataset\n",
    "    logger.info(f'Loading FiftyOne dataset \"{FO_DATASET_NAME}\"')\n",
    "    dataset = fo.load_dataset(FO_DATASET_NAME)\n",
    "    logger.info(f'    Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}')\n",
    "\n",
    "    # Launch FiftyOne app in browser\n",
    "    logger.info(f'Launching FifyOne app in browser')\n",
    "    session = fo.launch_app(dataset, auto=False)\n",
    "    logger.info(session)\n",
    "\n",
    "logger.info('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.info['notes'] = 'Here is another note about this dataset.' \n",
    "# dataset.save()\n",
    "# dataset.info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
