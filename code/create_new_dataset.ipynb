{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "Clone the repo\n",
    "```\n",
    "git clone https://github.com/aubreymoore/CRB-Damage-Dataset-Improvement\n",
    "```\n",
    "\n",
    "Move to the new folder\n",
    "```\n",
    "cd CRB-Damage-Dataset-Improvement\n",
    "```\n",
    "\n",
    "Create a virtual environment\n",
    "```\n",
    "python3 -m venv .venv\n",
    "```\n",
    "\n",
    "Activate the new virtual environment\n",
    "```\n",
    "source venv/bin/activate\n",
    "```\n",
    "\n",
    "Install required python modules\n",
    "```\n",
    "pip install -r code/requirements.txt\n",
    "```\n",
    "\n",
    "Create a .gitignore file and add .venv to the list of files and folders to be ignored.\n",
    "Adding a virtual environmant to a repository is bad practice.\n",
    "```\n",
    "echo \".venv\" >> .gitignore\n",
    "```\n",
    "\n",
    "# References\n",
    "\n",
    "https://pybit.es/articles/a-better-place-to-put-your-python-virtual-environments/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import fiftyone as fo\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_requirements_file():\n",
    "    os.system('pip list --format=freeze > requirements.txt')\n",
    "\n",
    "# update_requirements_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_dataset(original_ds_path, new_ds_path):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    os.mkdir(new_ds_path)\n",
    "    os.mkdir(f'{new_ds_path}/images')\n",
    "    os.mkdir(f'{new_ds_path}/images/train')\n",
    "    os.mkdir(f'{new_ds_path}/images/val')\n",
    "    os.mkdir(f'{new_ds_path}/labels')\n",
    "    os.mkdir(f'{new_ds_path}/labels/train')\n",
    "    os.mkdir(f'{new_ds_path}/labels/val')\n",
    "    \n",
    "    for filepath in glob.glob(f'{original_ds_path}/train/*.jpg'):\n",
    "        shutil.copy2(filepath, f'{new_ds_path}/images/train')\n",
    "    for filepath in glob.glob(f'{original_ds_path}/train/*.txt'):\n",
    "        shutil.copy2(filepath, f'{new_ds_path}/labels/train')\n",
    "    for filepath in glob.glob(f'{original_ds_path}/val/*.jpg'):\n",
    "        shutil.copy2(filepath, f'{new_ds_path}/images/val')\n",
    "    for filepath in glob.glob(f'{original_ds_path}/val/*.txt'):\n",
    "        shutil.copy2(filepath, f'{new_ds_path}/labels/val')\n",
    "        \n",
    "    s = f'path: {new_ds_path} \\n'\n",
    "    s += 'train: ./images/train/ \\n'\n",
    "    s += 'val: ./images/val/ \\n'\n",
    "    s += 'names: \\n'\n",
    "    s += '  0: live \\n'\n",
    "    s += '  1: dead \\n'\n",
    "    s += '  2: vcut \\n'\n",
    "    with open(f'{new_ds_path}/dataset.yaml', 'w') as f:\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo2fiftyone(fo_dataset_name, dataset_dir, splits=[\"train\", \"val\"]):\n",
    "    \"\"\" \n",
    "    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n",
    "    \"\"\" \n",
    "    dataset = fo.Dataset(name, persistent=True)\n",
    "    for split in splits:\n",
    "        dataset.add_dir(\n",
    "            dataset_dir=dataset_dir,\n",
    "            dataset_type=fo.types.YOLOv5Dataset,\n",
    "            split=split,\n",
    "            tags=split,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datetime_tag():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_autocorrelated_images(dataset):\n",
    "    \"\"\" \n",
    "    \"\"\" \n",
    "    pass\n",
    "\n",
    "# import numpy as np\n",
    "# from numpy.linalg import norm\n",
    "\n",
    "# def cosine_similarity(a, b):\n",
    "#     return np.dot(a,b)/(norm(a)*norm(b))\n",
    " \n",
    "# # a = np.array([2,1,2,3,2,9])\n",
    "# # b = np.array([3,4,2,4,5,5])\n",
    "# # cosine_similarity(a, b)\n",
    "\n",
    "\n",
    "# sorted_by_datetime_view = dataset.load_saved_view('sorted_by_datatime_view')\n",
    "\n",
    "# thresh = 0.92\n",
    "\n",
    "# first_sample = True\n",
    "# for sample in sorted_by_datetime_view:\n",
    "#     if first_sample:\n",
    "#         current_embeddings = sample.embeddings\n",
    "#         similarity = 0.0\n",
    "#         first_sample = False\n",
    "#     else:\n",
    "#         previous_embeddings = current_embeddings\n",
    "#         current_embeddings = sample.embeddings\n",
    "#         similarity = cosine_similarity(previous_embeddings, current_embeddings)\n",
    "#         sample['similarity_with_prev_img'] = similarity\n",
    "#     if similarity > thresh:\n",
    "#         sample.tags.append(f'similarity>{thresh}')\n",
    "#     else:\n",
    "#         sample.tags.append('similarity OK') \n",
    "#     sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{3365230751.py:22} INFO - /home/aubrey/datasets/Guam07v3 already exists in YOLOv5 format\n",
      "[{3365230751.py:30} INFO - FiftyOne dataset \"Guam07v3\" already exists\n",
      "[{3365230751.py:36} INFO - Loading FiftyOne dataset \"Guam07v3\"\n",
      "[{3365230751.py:38} INFO - Name:        Guam07v3\n",
      "Media type:  image\n",
      "Num samples: 10414\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "[{3365230751.py:39} INFO - Launching FifyOne app in browser\n",
      "Session launched. Run `session.show()` to open the App in a cell output.\n",
      "[{session.py:213} INFO - Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset:          Guam07v3\n",
       "Media type:       image\n",
       "Num samples:      10414\n",
       "Selected samples: 0\n",
       "Selected labels:  0\n",
       "Session URL:      http://localhost:5151/"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAIN\n",
    "original_ds_path = '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks'\n",
    "new_ds_path = '/home/aubrey/datasets/Guam07v3'\n",
    "fo_dataset_name = 'Guam07v3'\n",
    "logfile = 'create_new_dataset.log'\n",
    "\n",
    "# Set up logger to log to notebook and logfile\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG, \n",
    "    format='[%(asctime)s] {%(pathname)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    datefmt='%H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler(filename=logfile),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# wrangle dataset into YOLOv5 format\n",
    "\n",
    "if os.path.exists(new_ds_path):\n",
    "    logger.info(f'{new_ds_path} already exists in YOLOv5 format')\n",
    "else:\n",
    "    logger.info(f'creating dataset \"{new_ds_path}\" in YOLOv5 format')\n",
    "    create_new_dataset(original_ds_path, new_ds_path)\n",
    "\n",
    "# Create new FiftyOne dataset\n",
    "\n",
    "if fo_dataset_name in fo.list_datasets():\n",
    "    logger.info(f'FiftyOne dataset \"{fo_dataset_name}\" already exists') \n",
    "else:\n",
    "    dataset = yolo2fiftyone(name=fo_dataset_name, dataset_dir=new_ds_path)\n",
    "\n",
    "# Load FiftyOne dataset and launch FiftyOne app in browser\n",
    "\n",
    "logger.info(f'Loading FiftyOne dataset \"{fo_dataset_name}\"')\n",
    "dataset = fo.load_dataset(fo_dataset_name)\n",
    "logger.info(dataset)\n",
    "logger.info(f'Launching FifyOne app in browser')\n",
    "fo.launch_app(dataset, auto=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
