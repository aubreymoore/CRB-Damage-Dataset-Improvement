{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "Clone the repo\n",
    "```\n",
    "git clone https://github.com/aubreymoore/CRB-Damage-Dataset-Improvement\n",
    "```\n",
    "\n",
    "Move to the new folder\n",
    "```\n",
    "cd CRB-Damage-Dataset-Improvement\n",
    "```\n",
    "\n",
    "Create a virtual environment\n",
    "```\n",
    "python3 -m venv .venv\n",
    "```\n",
    "\n",
    "Activate the new virtual environment\n",
    "```\n",
    "source venv/bin/activate\n",
    "```\n",
    "\n",
    "Install required python modules\n",
    "```\n",
    "pip install -r code/requirements.txt\n",
    "```\n",
    "\n",
    "Create a .gitignore file and add .venv to the list of files and folders to be ignored.\n",
    "Adding a virtual environmant to a repository is bad practice.\n",
    "```\n",
    "echo \".venv\" >> .gitignore\n",
    "```\n",
    "\n",
    "# References\n",
    "\n",
    "https://pybit.es/articles/a-better-place-to-put-your-python-virtual-environments/\n",
    "\n",
    "[Image Deduplication](https://github.com/voxel51/fiftyone-examples/blob/master/examples/image_deduplication.ipynb)\n",
    "\n",
    "[CVAT <> FiftyOne: Data-Centric Machine Learning with Two Open Source Tools](https://www.cvat.ai/post/data-centric)\n",
    "\n",
    "[FiftyOne - Ultralytics Integration](https://docs.voxel51.com/integrations/ultralytics.html)\n",
    "\n",
    "[Finding Detection Mistakes with FiftyOne](https://docs.voxel51.com/tutorials/detection_mistakes.html)\n",
    "\n",
    "[Fine-tune YOLOv8 models for custom use cases with the help of FiftyOne](https://docs.voxel51.com/tutorials/yolov8.html)\n",
    "\n",
    "[FiftyOne Brain](https://docs.voxel51.com/brain.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "import logging\n",
    "import sys\n",
    "from icecream import ic\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_timestamp_field():\n",
    "    dataset.add_sample_field(\"timestamp\", fo.DateTimeField)\n",
    "\n",
    "    for sample in dataset:\n",
    "        timestamp_str = os.path.basename(sample.filepath)[4:-4]\n",
    "        dt = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')\n",
    "        # ic(timestamp_str, dt)\n",
    "        sample['timestamp'] = dt\n",
    "        sample.save()\n",
    "    \n",
    "    # Create view  \n",
    "    view = dataset.sort_by(F'timestamp')\n",
    "    dataset.save_view('sorted_by_timestamp', view, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_requirements_file():\n",
    "    os.system('pip list --format=freeze > requirements.txt')\n",
    "\n",
    "# update_requirements_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_dataset(original_ds_path, new_ds_path):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    os.mkdir(new_ds_path)\n",
    "    os.mkdir(f'{new_ds_path}/images')\n",
    "    os.mkdir(f'{new_ds_path}/images/train')\n",
    "    os.mkdir(f'{new_ds_path}/images/val')\n",
    "    os.mkdir(f'{new_ds_path}/labels')\n",
    "    os.mkdir(f'{new_ds_path}/labels/train')\n",
    "    os.mkdir(f'{new_ds_path}/labels/val')\n",
    "    \n",
    "    for filepath in glob.glob(f'{original_ds_path}/train/*.jpg'):\n",
    "        shutil.copy2(filepath, f'{new_ds_path}/images/train')\n",
    "    for filepath in glob.glob(f'{original_ds_path}/train/*.txt'):\n",
    "        shutil.copy2(filepath, f'{new_ds_path}/labels/train')\n",
    "    for filepath in glob.glob(f'{original_ds_path}/val/*.jpg'):\n",
    "        shutil.copy2(filepath, f'{new_ds_path}/images/val')\n",
    "    for filepath in glob.glob(f'{original_ds_path}/val/*.txt'):\n",
    "        shutil.copy2(filepath, f'{new_ds_path}/labels/val')\n",
    "        \n",
    "    s = f'path: {new_ds_path} \\n'\n",
    "    s += 'train: ./images/train/ \\n'\n",
    "    s += 'val: ./images/val/ \\n'\n",
    "    s += 'names: \\n'\n",
    "    s += '  0: live \\n'\n",
    "    s += '  1: dead \\n'\n",
    "    s += '  2: vcut \\n'\n",
    "    with open(f'{new_ds_path}/dataset.yaml', 'w') as f:\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo2fiftyone(fo_dataset_name, dataset_dir, splits=[\"train\", \"val\"]):\n",
    "    \"\"\" \n",
    "    Imports a dataset in YOLO5 format into FiftyOne, using tags to mark the samples in each split \n",
    "    \"\"\" \n",
    "    dataset = fo.Dataset(name, persistent=True)\n",
    "    for split in splits:\n",
    "        dataset.add_dir(\n",
    "            dataset_dir=dataset_dir,\n",
    "            dataset_type=fo.types.YOLOv5Dataset,\n",
    "            split=split,\n",
    "            tags=split,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings_field():\n",
    "    \"\"\" \n",
    "    \"\"\" \n",
    "    model = foz.load_zoo_model(\"mobilenet-v2-imagenet-torch\")\n",
    "    dataset.compute_embeddings(model=model, embeddings_field='embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a,b)/(norm(a)*norm(b))\n",
    " \n",
    "# a = np.array([2,1,2,3,2,9])\n",
    "# b = np.array([3,4,2,4,5,5])\n",
    "# cosine_similarity(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_similarity_with_prev_img_field():\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    view = dataset.load_saved_view('sorted_by_timestamp')\n",
    "    # thresh = 0.92\n",
    "    first_sample = True\n",
    "    for sample in view:\n",
    "        if first_sample:\n",
    "            current_embeddings = sample.embeddings\n",
    "            similarity = 0.0\n",
    "            first_sample = False\n",
    "        else:\n",
    "            previous_embeddings = current_embeddings\n",
    "            current_embeddings = sample.embeddings\n",
    "            similarity = cosine_similarity(previous_embeddings, current_embeddings)\n",
    "        sample['similarity_with_prev_img'] = similarity\n",
    "        # if similarity > thresh:\n",
    "        #     sample.tags.append(f'similarity>{thresh}')\n",
    "        # else:\n",
    "        #     sample.tags.append('similarity OK') \n",
    "        sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions_field():\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    # Load YOLOv8 model\n",
    "    # from ultralytics import YOLO\n",
    "    model = YOLO(ORIGINAL_MODEL_PATH)\n",
    "    dataset.apply_model(model, label_field=\"yolov8\")\n",
    "    \n",
    "# add_predictions_field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mistakenness_field():\n",
    "    \"\"\" \n",
    "    Adds mistakenness, possible_missing and possible_spurious fields.\n",
    "    See docs at https://docs.voxel51.com/brain.html#label-mistakes for details.\n",
    "    \"\"\"\n",
    "    fob.compute_mistakenness(dataset, \"yolov8\", label_field=\"ground_truth\")  \n",
    "    \n",
    "# add_mistakenness_field() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_field(fieldname, func):\n",
    "    \"\"\" \n",
    "    This utility function checks for existence of a field in a dataset.\n",
    "    If the field does not exist it is added by running func.\n",
    "    \"\"\"\n",
    "    if dataset.get_field(fieldname):\n",
    "        logger.info(f'\"{fieldname}\" field already exists')\n",
    "    else:\n",
    "        logger.info(f'Adding \"{fieldname}\" field')\n",
    "        func()\n",
    "\n",
    "# def add_new_field():\n",
    "#     \"\"\" \n",
    "#     Code for adding a field named 'new' should be inserted in this function.\n",
    "#     \"\"\"\n",
    "#     pass\n",
    "    \n",
    "# add_field('new', add_new_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autocorrelated_images_view(threshold, delete=False):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    dataset = fo.load_dataset(fo_dataset_name)\n",
    "    sorted_by_timestamp_view = dataset.load_saved_view('sorted_by_timestamp')\n",
    "    view = sorted_by_timestamp_view.match(\n",
    "        F('similarity_with_prev_img') > threshold)\n",
    "    dataset.save_view(\"autocorrelated_images_view\", view, overwrite=True)\n",
    "    count = view.count()\n",
    "    \n",
    "    if delete:\n",
    "        dataset.delete_samples(view) \n",
    "        dataset.save()\n",
    "     \n",
    "    return count\n",
    "  \n",
    "# create_autocorrelated_images_view(0.98, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ground_truth_bbs(dataset):\n",
    "    total_detections = 0\n",
    "    for sample in dataset:\n",
    "        total_detections += len(sample.ground_truth.detections)\n",
    "    return total_detections\n",
    "\n",
    "# count_ground_truth_bbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bb_touching_edge_view(delete=False):\n",
    "    \"\"\" \n",
    "    https://docs.voxel51.com/recipes/remove_duplicate_annos.html\n",
    "    \"\"\"\n",
    "    dataset = fo.load_dataset(fo_dataset_name)\n",
    "    view = dataset.filter_labels('ground_truth', \n",
    "        (F('bounding_box')[0] <= 0) | # left\n",
    "        (F('bounding_box')[1] <= 0) | # top\n",
    "        ((F('bounding_box')[0] + F('bounding_box')[3]) >= 1) # right\n",
    "    )\n",
    "    dataset.save_view('bb_touching_edge', view, overwrite=True) \n",
    "    count = view.count()\n",
    "           \n",
    "    if delete:\n",
    "        dataset.delete_labels(view)\n",
    "    dataset.save()\n",
    "            \n",
    "    return  count\n",
    "\n",
    "# create_bb_touching_edge_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logger(logfile):\n",
    "    \"\"\"\n",
    "    Configure logger to send messages to notebook and logfile\n",
    "    \"\"\"\n",
    "    logging.root.handlers = []\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO, \n",
    "        format='%(asctime)s %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "            logging.FileHandler(filename=logfile),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    "    logger = logging.getLogger()\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-24 16:24:42 Updating \"requirements.txt\"\n",
      "2024-11-24 16:24:42 \"/home/aubrey/datasets/Guam07v3\" already exists in YOLOv5 format\n",
      "2024-11-24 16:24:44 FiftyOne dataset \"Guam07v3\" already exists\n",
      "2024-11-24 16:24:44 Loading FiftyOne dataset \"Guam07v3\"\n",
      "2024-11-24 16:24:51 Ground truth bounding boxes: 14807\n",
      "2024-11-24 16:24:51 \"timestamp\" field already exists\n",
      "2024-11-24 16:24:51 \"embeddings\" field already exists\n",
      "2024-11-24 16:24:51 \"similarity_with_prev_img\" field already exists\n",
      "2024-11-24 16:24:51 \"yolov8\" field already exists\n",
      "2024-11-24 16:24:51 \"mistakenness\" field already exists\n",
      "2024-11-24 16:24:51 Creating \"bb_touching_edge_view\"\n",
      "2024-11-24 16:24:51     \"DELETE_BBS_TOUCHING_EDGES\" is True; bbs will be deleted\n",
      "2024-11-24 16:24:51     0 ground truth bounding boxes touching image edges were found\n",
      "2024-11-24 16:24:51 Creating \"autocorrelated_images_view\"\n",
      "2024-11-24 16:24:51     \"DELETE_AUTOCORRELATED_IMAGES\" is True; samples will be deleted\n",
      "2024-11-24 16:24:51 With a threshold of 0.98, 0 autocorrelated images were found\n",
      "2024-11-24 16:24:51 Loading FiftyOne dataset \"Guam07v3\"\n",
      "2024-11-24 16:24:57 Ground truth bounding boxes: 14807\n",
      "2024-11-24 16:24:57 Launching FifyOne app in browser\n",
      "Session launched. Run `session.show()` to open the App in a cell output.\n",
      "2024-11-24 16:25:00 Session launched. Run `session.show()` to open the App in a cell output.\n",
      "2024-11-24 16:25:00 Dataset:          Guam07v3\n",
      "Media type:       image\n",
      "Num samples:      8959\n",
      "Selected samples: 0\n",
      "Selected labels:  0\n",
      "Session URL:      http://localhost:5151/\n",
      "2024-11-24 16:25:00 FINISHED\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "# Constants\n",
    "\n",
    "original_ds_path = '/home/aubrey/Desktop/Guam07-training-set/datasets/3class-no-symlinks'\n",
    "ORIGINAL_MODEL_PATH = f'{original_ds_path}/runs/detect/train5/weights/best.pt'\n",
    "new_ds_path = '/home/aubrey/datasets/Guam07v3'\n",
    "fo_dataset_name = 'Guam07v3'\n",
    "logfile = 'create_new_dataset.log'\n",
    "AUTOCORRELATED_IMAGES_THRESHOLD = 0.98\n",
    "DELETE_AUTOCORRELATED_IMAGES = True\n",
    "DELETE_BBS_TOUCHING_EDGES = True\n",
    "\n",
    "#configure logger\n",
    "logger = configure_logger(logfile)\n",
    "\n",
    "# update requirements.txt\n",
    "logger.info('Updating \"requirements.txt\"')\n",
    "update_requirements_file()\n",
    "\n",
    "# wrangle dataset into YOLOv5 format\n",
    "if os.path.exists(new_ds_path):\n",
    "    logger.info(f'\"{new_ds_path}\" already exists in YOLOv5 format')\n",
    "else:\n",
    "    logger.info(f'creating dataset \"{new_ds_path}\" in YOLOv5 format')\n",
    "    create_new_dataset(original_ds_path, new_ds_path)\n",
    "\n",
    "# Create new FiftyOne dataset\n",
    "if fo_dataset_name in fo.list_datasets():\n",
    "    logger.info(f'FiftyOne dataset \"{fo_dataset_name}\" already exists') \n",
    "else:\n",
    "    logger.info(f'Creating FiftyOne dataset \"{fo_dataset_name}\"')\n",
    "    dataset = yolo2fiftyone(name=fo_dataset_name, dataset_dir=new_ds_path)\n",
    "    \n",
    "# Load dataset\n",
    "logger.info(f'Loading FiftyOne dataset \"{fo_dataset_name}\"')\n",
    "dataset = fo.load_dataset(fo_dataset_name)\n",
    "logger.info(f'Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}')\n",
    "\n",
    "# Add fields if they don't already exist\n",
    "add_field('timestamp', add_timestamp_field)\n",
    "add_field('embeddings', add_embeddings_field)\n",
    "add_field('similarity_with_prev_img', add_similarity_with_prev_img_field)\n",
    "add_field('yolov8', add_predictions_field)\n",
    "add_field('mistakenness', add_mistakenness_field)\n",
    "\n",
    "# Find bounding boxes touching left, top or right edges of images\n",
    "logger.info('Creating \"bb_touching_edge_view\"')\n",
    "if DELETE_BBS_TOUCHING_EDGES:\n",
    "    logger.info('    \"DELETE_BBS_TOUCHING_EDGES\" is True; bbs will be deleted')\n",
    "else:\n",
    "    logger.info('    \"DELETE_BBS_TOUCHING_EDGES\" is False; bbs will not be deleted')\n",
    "bb_touching_edge_count = create_bb_touching_edge_view(DELETE_BBS_TOUCHING_EDGES)\n",
    "logger.info(f'    {bb_touching_edge_count} ground truth bounding boxes touching image edges were found')\n",
    "\n",
    "# Find autocorrelated images\n",
    "logger.info('Creating \"autocorrelated_images_view\"')\n",
    "if DELETE_BBS_TOUCHING_EDGES:\n",
    "    logger.info('    \"DELETE_AUTOCORRELATED_IMAGES\" is True; samples will be deleted')\n",
    "else:\n",
    "    logger.info('    \"DELETE_AUTOCORRELATED_IMAGES\" is False; bbs will not be deleted')\n",
    "autocorrelated_image_count = create_autocorrelated_images_view(\n",
    "    threshold=AUTOCORRELATED_IMAGES_THRESHOLD, delete=DELETE_AUTOCORRELATED_IMAGES)\n",
    "logger.info(f'With a threshold of {AUTOCORRELATED_IMAGES_THRESHOLD}, {autocorrelated_image_count} autocorrelated images were found')\n",
    "\n",
    "# Reoad dataset\n",
    "logger.info(f'Loading FiftyOne dataset \"{fo_dataset_name}\"')\n",
    "dataset = fo.load_dataset(fo_dataset_name)\n",
    "logger.info(f'Ground truth bounding boxes: {count_ground_truth_bbs(dataset)}')\n",
    "\n",
    "# Launch FiftyOne app in browser\n",
    "logger.info(f'Launching FifyOne app in browser')\n",
    "session = fo.launch_app(dataset, auto=False)\n",
    "logger.info(session)\n",
    "\n",
    "logger.info('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.info['notes'] = 'Here is another note about this dataset.' \n",
    "# dataset.save()\n",
    "# dataset.info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
